2025-10-08 19:54:16,907 [INFO] werkzeug: [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://localhost:8080
2025-10-08 19:54:16,907 [INFO] werkzeug: [33mPress CTRL+C to quit[0m
2025-10-08 19:54:16,908 [INFO] werkzeug:  * Restarting with stat
2025-10-08 19:54:17,839 [WARNING] werkzeug:  * Debugger is active!
2025-10-08 19:54:17,847 [INFO] werkzeug:  * Debugger PIN: 246-503-739
2025-10-08 19:55:14,134 [INFO] src.api.app: üåê OPTIONS /api/jobs/similar - 127.0.0.1
2025-10-08 19:55:14,135 [INFO] src.api.app: ‚úÖ OPTIONS /api/jobs/similar - 200 - 0.002s
2025-10-08 19:55:14,137 [INFO] werkzeug: 127.0.0.1 - - [08/Oct/2025 19:55:14] "OPTIONS /api/jobs/similar HTTP/1.1" 200 -
2025-10-08 19:55:14,139 [INFO] src.api.app: üåê POST /api/jobs/similar - 127.0.0.1
2025-10-08 19:55:14,140 [DEBUG] src.api.app: üìù Request data: {'job_description': 'About the job\nAbout Ascendion\nAscendion is a full-service digital engineering solutions company. We make and manage software platforms and products that power growth and deliver captivating experiences to consumers and employees. Our engineering, cloud, data, experience design, and talent solution capabilities accelerate transformation and impact for enterprise clients. Headquartered in New Jersey, our workforce of 6,000+ Ascenders delivers solutions from around the globe. Ascendion is built differently to engineer the next. Ascendion | Engineering to elevate life\nWe have a culture built on opportunity, inclusion, and a spirit of partnership. Come, change the world with us:\n¬∑ Build the coolest tech for world‚Äôs leading brands\n¬∑ Solve complex problems ‚Äì and learn new skills\n¬∑ Experience the power of transforming digital engineering for Fortune 500 clients\n¬∑ Master your craft with leading training programs and hands-on experience\nExperience a community of change makers!\nJoin a culture of high-performing innovators with endless ideas and a passion for tech. Our culture is the fabric of our company, and it is what makes us unique and diverse. The way we share ideas, learning, experiences, successes, and joy allows everyone to be their best at Ascendion.\nAbout the Role:\n\n\nJob Title : Python Developer\n\nLocation: Hybrid in Toronto, Canada\n\n \n\nLooking for Python Developer with Django, Flask and FastAPI\n\n\n\nSalary Range: The salary for this position is between $130,000 ‚Äì $140,000 annually. Factors which may affect pay within this range may include geography/market, skills, education, experience, and other qualifications of the successful candidate.\n\n\nBenefits: The Company offers the following benefits for this position, subject to applicable eligibility requirements: [medical insurance] [dental insurance] [vision insurance] [401(k) retirement plan] [long-term disability insurance] [short-term disability insurance] [5 personal days accrued each calendar year. The Paid time off benefits meet the paid sick and safe time laws that pertains to the City/ State] [10-15 days of paid vacation time] [6 paid holidays and 1 floating holiday per calendar year] [Ascendion Learning Management System]\n\n\nWant to change the world? Let us know.\nTell us about your experiences, education, and ambitions. Bring your knowledge, unique viewpoint, and creativity to the table. Let‚Äôs talk!', 'company_name': 'Ascendion', 'position_title': 'Python Developer'}
2025-10-08 19:55:14,365 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'idempotency_key': 'stainless-python-retry-7fa574e1-1fa0-4df8-9e13-70ee7705ab41', 'post_parser': <function Embeddings.create.<locals>.parser at 0x122d449a0>, 'json_data': {'input': 'Company: Ascendion. Position: Python Developer. Description: About the job\nAbout Ascendion\nAscendion is a full-service digital engineering solutions company. We make and manage software platforms and products that power growth and deliver captivating experiences to consumers and employees. Our engineering, cloud, data, experience design, and talent solution capabilities accelerate transformation and impact for enterprise clients. Headquartered in New Jersey, our workforce of 6,000+ Ascenders delivers solutions from around the globe. Ascendion is built differently to engineer the next. Ascendion | Engineering to elevate life\nWe have a culture built on opportunity, inclusion, and a spirit of partnership. Come, change the world with us:\n¬∑ Build the coolest tech for world‚Äôs leading brands\n¬∑ Solve complex problems ‚Äì and learn new skills\n¬∑ Experience the power of transforming digital engineering for Fortune 500 clients\n¬∑ Master your craft with leading training programs and hands-on experience\nExperience a community of change makers!\nJoin a culture of high-performing innovators with endless ideas and a passion for tech. Our culture is the fabric of our company, and it is what makes us unique and diverse. The way we share ideas, learning, experiences, successes, and joy allows everyone to be their best at Ascendion.\nAbout the Role:\n\n\nJob Title : Python Developer\n\nLocation: Hybrid in Toronto, Canada\n\n \n\nLooking for Python Developer with Django, Flask and FastAPI\n\n\n\nSalary Range: The salary for this position is between $130,000 ‚Äì $140,000 annually. Factors which may affect pay within this range may include geography/market, skills, education, experience, and other qualifications of the successful candidate.\n\n\nBenefits: The Company offers the following benefits for this position, subject to applicable eligibility requirements: [medical insurance] [dental insurance] [vision insurance] [401(k) retirement plan] [long-term disability insurance] [short-term disability insurance] [5 personal days accrued each calendar year. The Paid time off benefits meet the paid sick and safe time laws that pertains to the City/ State] [10-15 days of paid vacation time] [6 paid holidays and 1 floating holiday per calendar year] [Ascendion Learning Management System]\n\n\nWant to change the world? Let us know.\nTell us about your experiences, education, and ambitions. Bring your knowledge, unique viewpoint, and creativity to the table. Let‚Äôs talk!', 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}
2025-10-08 19:55:14,386 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2025-10-08 19:55:14,386 [DEBUG] httpcore.connection: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-10-08 19:55:14,483 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x125800d90>
2025-10-08 19:55:14,484 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x11224f260> server_hostname='api.openai.com' timeout=5.0
2025-10-08 19:55:14,527 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x125800d10>
2025-10-08 19:55:14,527 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-08 19:55:14,528 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-08 19:55:14,528 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-08 19:55:14,528 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-08 19:55:14,528 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-08 19:55:14,965 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 09 Oct 2025 00:55:15 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'personal-moaon6'), (b'openai-processing-ms', b'156'), (b'openai-project', b'proj_xpqpZ6mXeDEwLbfYGvXUcwd5'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-797b6d7f75-2wfcj'), (b'x-envoy-upstream-service-time', b'324'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999384'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'36ms'), (b'x-request-id', b'req_8874743cc20a4691bf954d3a9e8185fb'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=nfw46w2BquFocVYX3O8u3TI.H_oEwYifrI7i5mTXfks-1759971315-1.0.1.1-EtgHyT_Bj5HAHhCUqgE6rtEXY2PjZs2yvpNfiHPIlpF0riI2lTK1LRrjuUAJUesGATn0ZzjbsfcOwfdiXIx7wqmta6m5JF5YqbfReAFa570; path=/; expires=Thu, 09-Oct-25 01:25:15 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=VeGn4TqErzuGaMMLH9jwTGW6dubpWWLpKVv2_RbHmys-1759971315043-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'98b9e94c8aec89fb-ORD'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-10-08 19:55:14,969 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-10-08 19:55:14,971 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-08 19:55:14,972 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-08 19:55:14,972 [DEBUG] httpcore.http11: response_closed.started
2025-10-08 19:55:14,972 [DEBUG] httpcore.http11: response_closed.complete
2025-10-08 19:55:14,972 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers([('date', 'Thu, 09 Oct 2025 00:55:15 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-allow-origin', '*'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-model', 'text-embedding-3-small'), ('openai-organization', 'personal-moaon6'), ('openai-processing-ms', '156'), ('openai-project', 'proj_xpqpZ6mXeDEwLbfYGvXUcwd5'), ('openai-version', '2020-10-01'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('via', 'envoy-router-797b6d7f75-2wfcj'), ('x-envoy-upstream-service-time', '324'), ('x-ratelimit-limit-requests', '3000'), ('x-ratelimit-limit-tokens', '1000000'), ('x-ratelimit-remaining-requests', '2999'), ('x-ratelimit-remaining-tokens', '999384'), ('x-ratelimit-reset-requests', '20ms'), ('x-ratelimit-reset-tokens', '36ms'), ('x-request-id', 'req_8874743cc20a4691bf954d3a9e8185fb'), ('x-openai-proxy-wasm', 'v0.1'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=nfw46w2BquFocVYX3O8u3TI.H_oEwYifrI7i5mTXfks-1759971315-1.0.1.1-EtgHyT_Bj5HAHhCUqgE6rtEXY2PjZs2yvpNfiHPIlpF0riI2lTK1LRrjuUAJUesGATn0ZzjbsfcOwfdiXIx7wqmta6m5JF5YqbfReAFa570; path=/; expires=Thu, 09-Oct-25 01:25:15 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=VeGn4TqErzuGaMMLH9jwTGW6dubpWWLpKVv2_RbHmys-1759971315043-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '98b9e94c8aec89fb-ORD'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-10-08 19:55:14,972 [DEBUG] openai._base_client: request_id: req_8874743cc20a4691bf954d3a9e8185fb
2025-10-08 19:55:15,002 [INFO] src.api.app: ‚úÖ POST /api/jobs/similar - 200 - 0.862s
2025-10-08 19:55:15,002 [INFO] werkzeug: 127.0.0.1 - - [08/Oct/2025 19:55:15] "POST /api/jobs/similar HTTP/1.1" 200 -
2025-10-08 19:55:20,577 [INFO] src.api.app: üåê OPTIONS /api/generate/cover-letter/ - 127.0.0.1
2025-10-08 19:55:20,578 [INFO] src.api.app: ‚úÖ OPTIONS /api/generate/cover-letter/ - 200 - 0.001s
2025-10-08 19:55:20,578 [INFO] werkzeug: 127.0.0.1 - - [08/Oct/2025 19:55:20] "OPTIONS /api/generate/cover-letter/ HTTP/1.1" 200 -
2025-10-08 19:55:20,581 [INFO] src.api.app: üåê POST /api/generate/cover-letter/ - 127.0.0.1
2025-10-08 19:55:20,581 [DEBUG] src.api.app: üìù Request data: {'jobDescription': 'About the job\nAbout Ascendion\nAscendion is a full-service digital engineering solutions company. We make and manage software platforms and products that power growth and deliver captivating experiences to consumers and employees. Our engineering, cloud, data, experience design, and talent solution capabilities accelerate transformation and impact for enterprise clients. Headquartered in New Jersey, our workforce of 6,000+ Ascenders delivers solutions from around the globe. Ascendion is built differently to engineer the next. Ascendion | Engineering to elevate life\nWe have a culture built on opportunity, inclusion, and a spirit of partnership. Come, change the world with us:\n¬∑ Build the coolest tech for world‚Äôs leading brands\n¬∑ Solve complex problems ‚Äì and learn new skills\n¬∑ Experience the power of transforming digital engineering for Fortune 500 clients\n¬∑ Master your craft with leading training programs and hands-on experience\nExperience a community of change makers!\nJoin a culture of high-performing innovators with endless ideas and a passion for tech. Our culture is the fabric of our company, and it is what makes us unique and diverse. The way we share ideas, learning, experiences, successes, and joy allows everyone to be their best at Ascendion.\nAbout the Role:\n\n\nJob Title : Python Developer\n\nLocation: Hybrid in Toronto, Canada\n\n \n\nLooking for Python Developer with Django, Flask and FastAPI\n\n\n\nSalary Range: The salary for this position is between $130,000 ‚Äì $140,000 annually. Factors which may affect pay within this range may include geography/market, skills, education, experience, and other qualifications of the successful candidate.\n\n\nBenefits: The Company offers the following benefits for this position, subject to applicable eligibility requirements: [medical insurance] [dental insurance] [vision insurance] [401(k) retirement plan] [long-term disability insurance] [short-term disability insurance] [5 personal days accrued each calendar year. The Paid time off benefits meet the paid sick and safe time laws that pertains to the City/ State] [10-15 days of paid vacation time] [6 paid holidays and 1 floating holiday per calendar year] [Ascendion Learning Management System]\n\n\nWant to change the world? Let us know.\nTell us about your experiences, education, and ambitions. Bring your knowledge, unique viewpoint, and creativity to the table. Let‚Äôs talk!', 'companyName': 'Ascendion', 'positionTitle': 'Python Developer', 'resumePdfFile': 'http://localhost:8080/api/resumes/generated/Ascendion/Python%20Developer.pdf'}
2025-10-08 19:55:20,625 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'idempotency_key': 'stainless-python-retry-47d4d515-2aca-45b9-a976-a74486da797a', 'post_parser': <function Embeddings.create.<locals>.parser at 0x111096de0>, 'json_data': {'input': 'Company: Ascendion. Position: Python Developer. Description: About the job\nAbout Ascendion\nAscendion is a full-service digital engineering solutions company. We make and manage software platforms and products that power growth and deliver captivating experiences to consumers and employees. Our engineering, cloud, data, experience design, and talent solution capabilities accelerate transformation and impact for enterprise clients. Headquartered in New Jersey, our workforce of 6,000+ Ascenders delivers solutions from around the globe. Ascendion is built differently to engineer the next. Ascendion | Engineering to elevate life\nWe have a culture built on opportunity, inclusion, and a spirit of partnership. Come, change the world with us:\n¬∑ Build the coolest tech for world‚Äôs leading brands\n¬∑ Solve complex problems ‚Äì and learn new skills\n¬∑ Experience the power of transforming digital engineering for Fortune 500 clients\n¬∑ Master your craft with leading training programs and hands-on experience\nExperience a community of change makers!\nJoin a culture of high-performing innovators with endless ideas and a passion for tech. Our culture is the fabric of our company, and it is what makes us unique and diverse. The way we share ideas, learning, experiences, successes, and joy allows everyone to be their best at Ascendion.\nAbout the Role:\n\n\nJob Title : Python Developer\n\nLocation: Hybrid in Toronto, Canada\n\n \n\nLooking for Python Developer with Django, Flask and FastAPI\n\n\n\nSalary Range: The salary for this position is between $130,000 ‚Äì $140,000 annually. Factors which may affect pay within this range may include geography/market, skills, education, experience, and other qualifications of the successful candidate.\n\n\nBenefits: The Company offers the following benefits for this position, subject to applicable eligibility requirements: [medical insurance] [dental insurance] [vision insurance] [401(k) retirement plan] [long-term disability insurance] [short-term disability insurance] [5 personal days accrued each calendar year. The Paid time off benefits meet the paid sick and safe time laws that pertains to the City/ State] [10-15 days of paid vacation time] [6 paid holidays and 1 floating holiday per calendar year] [Ascendion Learning Management System]\n\n\nWant to change the world? Let us know.\nTell us about your experiences, education, and ambitions. Bring your knowledge, unique viewpoint, and creativity to the table. Let‚Äôs talk!', 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}
2025-10-08 19:55:20,625 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2025-10-08 19:55:20,626 [DEBUG] httpcore.connection: close.started
2025-10-08 19:55:20,626 [DEBUG] httpcore.connection: close.complete
2025-10-08 19:55:20,626 [DEBUG] httpcore.connection: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-10-08 19:55:20,661 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x125828310>
2025-10-08 19:55:20,662 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x11224f260> server_hostname='api.openai.com' timeout=5.0
2025-10-08 19:55:20,695 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x122d517d0>
2025-10-08 19:55:20,695 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-08 19:55:20,696 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-08 19:55:20,696 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-08 19:55:20,696 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-08 19:55:20,696 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-08 19:55:20,983 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 09 Oct 2025 00:55:21 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'personal-moaon6'), (b'openai-processing-ms', b'78'), (b'openai-project', b'proj_xpqpZ6mXeDEwLbfYGvXUcwd5'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-6c4c9cd988-x9659'), (b'x-envoy-upstream-service-time', b'174'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999384'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'36ms'), (b'x-request-id', b'req_16d584d2f04f4aa385767a485a6d590c'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'98b9e97329fe4848-ORD'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-10-08 19:55:20,985 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-10-08 19:55:20,985 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-08 19:55:20,986 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-08 19:55:20,986 [DEBUG] httpcore.http11: response_closed.started
2025-10-08 19:55:20,986 [DEBUG] httpcore.http11: response_closed.complete
2025-10-08 19:55:20,987 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers({'date': 'Thu, 09 Oct 2025 00:55:21 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-3-small', 'openai-organization': 'personal-moaon6', 'openai-processing-ms': '78', 'openai-project': 'proj_xpqpZ6mXeDEwLbfYGvXUcwd5', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'via': 'envoy-router-6c4c9cd988-x9659', 'x-envoy-upstream-service-time': '174', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '1000000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '999384', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '36ms', 'x-request-id': 'req_16d584d2f04f4aa385767a485a6d590c', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '98b9e97329fe4848-ORD', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-10-08 19:55:20,987 [DEBUG] openai._base_client: request_id: req_16d584d2f04f4aa385767a485a6d590c
2025-10-08 19:55:21,117 [INFO] chromadb.telemetry.product.posthog: Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-10-08 19:55:21,143 [DEBUG] chromadb.config: Starting component System
2025-10-08 19:55:21,143 [DEBUG] chromadb.config: Starting component Posthog
2025-10-08 19:55:21,143 [DEBUG] chromadb.config: Starting component OpenTelemetryClient
2025-10-08 19:55:21,143 [DEBUG] chromadb.config: Starting component FastAPI
2025-10-08 19:55:21,143 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=8000 local_address=None timeout=None socket_options=None
2025-10-08 19:55:21,144 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x12581be90>
2025-10-08 19:55:21,144 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-08 19:55:21,144 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-08 19:55:21,144 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-08 19:55:21,145 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-08 19:55:21,145 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-08 19:55:21,156 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'content-type', b'application/json'), (b'content-length', b'73'), (b'date', b'Thu, 09 Oct 2025 00:55:21 GMT')])
2025-10-08 19:55:21,157 [INFO] httpx: HTTP Request: GET http://localhost:8000/api/v2/auth/identity "HTTP/1.1 200 OK"
2025-10-08 19:55:21,157 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-08 19:55:21,157 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-08 19:55:21,157 [DEBUG] httpcore.http11: response_closed.started
2025-10-08 19:55:21,157 [DEBUG] httpcore.http11: response_closed.complete
2025-10-08 19:55:21,157 [INFO] chromadb.telemetry.product.posthog: Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-10-08 19:55:21,163 [DEBUG] chromadb.config: Starting component System
2025-10-08 19:55:21,164 [DEBUG] chromadb.config: Starting component Posthog
2025-10-08 19:55:21,164 [DEBUG] chromadb.config: Starting component OpenTelemetryClient
2025-10-08 19:55:21,164 [DEBUG] chromadb.config: Starting component FastAPI
2025-10-08 19:55:21,164 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=8000 local_address=None timeout=None socket_options=None
2025-10-08 19:55:21,164 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x125e307d0>
2025-10-08 19:55:21,165 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-08 19:55:21,165 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-08 19:55:21,165 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-08 19:55:21,165 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-08 19:55:21,165 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-08 19:55:21,173 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'content-type', b'application/json'), (b'content-length', b'46'), (b'date', b'Thu, 09 Oct 2025 00:55:21 GMT')])
2025-10-08 19:55:21,173 [INFO] httpx: HTTP Request: GET http://localhost:8000/api/v2/tenants/default_tenant "HTTP/1.1 200 OK"
2025-10-08 19:55:21,173 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-08 19:55:21,173 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-08 19:55:21,173 [DEBUG] httpcore.http11: response_closed.started
2025-10-08 19:55:21,173 [DEBUG] httpcore.http11: response_closed.complete
2025-10-08 19:55:21,174 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-08 19:55:21,174 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-08 19:55:21,174 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-08 19:55:21,174 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-08 19:55:21,174 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-08 19:55:21,175 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'content-type', b'application/json'), (b'content-length', b'97'), (b'date', b'Thu, 09 Oct 2025 00:55:21 GMT')])
2025-10-08 19:55:21,175 [INFO] httpx: HTTP Request: GET http://localhost:8000/api/v2/tenants/default_tenant/databases/default_database "HTTP/1.1 200 OK"
2025-10-08 19:55:21,175 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-08 19:55:21,175 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-08 19:55:21,175 [DEBUG] httpcore.http11: response_closed.started
2025-10-08 19:55:21,175 [DEBUG] httpcore.http11: response_closed.complete
2025-10-08 19:55:21,177 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-08 19:55:21,177 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-08 19:55:21,177 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-08 19:55:21,177 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-08 19:55:21,177 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-08 19:55:21,185 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'content-type', b'application/json'), (b'content-length', b'363'), (b'date', b'Thu, 09 Oct 2025 00:55:21 GMT')])
2025-10-08 19:55:21,186 [INFO] httpx: HTTP Request: POST http://localhost:8000/api/v2/tenants/default_tenant/databases/default_database/collections "HTTP/1.1 200 OK"
2025-10-08 19:55:21,186 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-08 19:55:21,186 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-08 19:55:21,186 [DEBUG] httpcore.http11: response_closed.started
2025-10-08 19:55:21,186 [DEBUG] httpcore.http11: response_closed.complete
2025-10-08 19:55:21,285 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'idempotency_key': 'stainless-python-retry-10baa437-47ac-42d6-9dce-e384a60b5c03', 'post_parser': <function Embeddings.create.<locals>.parser at 0x125e02de0>, 'json_data': {'input': [[10714, 279, 2683, 198, 10714, 40660, 408, 290, 198, 41203, 408, 290, 374, 264, 2539, 24358, 7528, 15009, 10105, 2883, 13, 1226, 1304, 323, 10299, 3241, 15771, 323, 3956, 430, 2410, 6650, 323, 6493, 86282, 11704, 311, 13723, 323, 8420, 13, 5751, 15009, 11, 9624, 11, 828, 11, 3217, 2955, 11, 323, 11005, 6425, 17357, 43880, 18475, 323, 5536, 369, 20790, 8403, 13, 11452, 68720, 304, 1561, 16228, 11, 1057, 32027, 315, 220, 21, 11, 931, 10, 40660, 14846, 28421, 10105, 505, 2212, 279, 24867, 13, 40660, 408, 290, 374, 5918, 1422, 2883, 25, 40660, 408, 290, 2361, 25, 13325, 25922]], 'model': 'text-embedding-3-large', 'encoding_format': 'base64'}}
2025-10-08 19:55:21,286 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2025-10-08 19:55:21,286 [DEBUG] httpcore.connection: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
2025-10-08 19:55:21,317 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x125e33d50>
2025-10-08 19:55:21,318 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x124266a80> server_hostname='api.openai.com' timeout=None
2025-10-08 19:55:21,358 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x125e33dd0>
2025-10-08 19:55:21,358 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-08 19:55:21,358 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-08 19:55:21,358 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-08 19:55:21,358 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-08 19:55:21,358 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-08 19:55:21,682 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): us.i.posthog.com:443
2025-10-08 19:55:21,752 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 09 Oct 2025 00:55:21 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-large'), (b'openai-organization', b'personal-moaon6'), (b'openai-processing-ms', b'90'), (b'openai-project', b'proj_xpqpZ6mXeDEwLbfYGvXUcwd5'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-5c84678cfc-5s675'), (b'x-envoy-upstream-service-time', b'289'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999899'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'6ms'), (b'x-request-id', b'req_835e7f0716124d5bbcdc0545d0a09457'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=hR6mthbAGO5jMXE864VeMi89O52H8XQ2J5ZzYaf8rF8-1759971321-1.0.1.1-b_eGYpB_n.kKlrqzhVzaTGeSdB2u.ryPf75ujllLggaisS.otpJ1n9vz12Bfgzr8mcX6FE9Edc0Q_9pg7JuDD..1EwYOG1XqWCXQKRi.D5I; path=/; expires=Thu, 09-Oct-25 01:25:21 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=FqRzgv_hytH0PGhAEHj3TXcBJRVlVUYqpyGYYKvamXc-1759971321834-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'98b9e9774da286ff-ORD'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-10-08 19:55:21,752 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-10-08 19:55:21,752 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-08 19:55:21,753 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-08 19:55:21,753 [DEBUG] httpcore.http11: response_closed.started
2025-10-08 19:55:21,753 [DEBUG] httpcore.http11: response_closed.complete
2025-10-08 19:55:21,753 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers([('date', 'Thu, 09 Oct 2025 00:55:21 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-allow-origin', '*'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-model', 'text-embedding-3-large'), ('openai-organization', 'personal-moaon6'), ('openai-processing-ms', '90'), ('openai-project', 'proj_xpqpZ6mXeDEwLbfYGvXUcwd5'), ('openai-version', '2020-10-01'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('via', 'envoy-router-5c84678cfc-5s675'), ('x-envoy-upstream-service-time', '289'), ('x-ratelimit-limit-requests', '3000'), ('x-ratelimit-limit-tokens', '1000000'), ('x-ratelimit-remaining-requests', '2999'), ('x-ratelimit-remaining-tokens', '999899'), ('x-ratelimit-reset-requests', '20ms'), ('x-ratelimit-reset-tokens', '6ms'), ('x-request-id', 'req_835e7f0716124d5bbcdc0545d0a09457'), ('x-openai-proxy-wasm', 'v0.1'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=hR6mthbAGO5jMXE864VeMi89O52H8XQ2J5ZzYaf8rF8-1759971321-1.0.1.1-b_eGYpB_n.kKlrqzhVzaTGeSdB2u.ryPf75ujllLggaisS.otpJ1n9vz12Bfgzr8mcX6FE9Edc0Q_9pg7JuDD..1EwYOG1XqWCXQKRi.D5I; path=/; expires=Thu, 09-Oct-25 01:25:21 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=FqRzgv_hytH0PGhAEHj3TXcBJRVlVUYqpyGYYKvamXc-1759971321834-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '98b9e9774da286ff-ORD'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-10-08 19:55:21,753 [DEBUG] openai._base_client: request_id: req_835e7f0716124d5bbcdc0545d0a09457
2025-10-08 19:55:21,755 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-08 19:55:21,755 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-08 19:55:21,755 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-08 19:55:21,755 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-08 19:55:21,755 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-08 19:55:21,768 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'content-type', b'application/json'), (b'content-length', b'6581'), (b'date', b'Thu, 09 Oct 2025 00:55:21 GMT')])
2025-10-08 19:55:21,768 [INFO] httpx: HTTP Request: POST http://localhost:8000/api/v2/tenants/default_tenant/databases/default_database/collections/87760c6d-637c-45d3-bbc4-b592e9ab0264/query "HTTP/1.1 200 OK"
2025-10-08 19:55:21,768 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-08 19:55:21,768 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-08 19:55:21,768 [DEBUG] httpcore.http11: response_closed.started
2025-10-08 19:55:21,768 [DEBUG] httpcore.http11: response_closed.complete
2025-10-08 19:55:21,772 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'idempotency_key': 'stainless-python-retry-89b840c9-a7cf-484e-b934-6465bc51589f', 'json_data': {'messages': [{'content': '\n    You are an expert cover letter writer specializing in creating compelling, personalized cover letters that effectively connect a candidate\'s background to specific job opportunities.\n\n    Your task is to analyze the job posting, personalized resume, and retrieved context to generate ONLY the cover letter content paragraphs in plain LaTeX format.\n\n    POSITION: Python Developer\n    COMPANY: Ascendion\n    JOB POSTING:\n    About the job\nAbout Ascendion\nAscendion is a full-service digital engineering solutions company. We make and manage software platforms and products that power growth and deliver captivating experiences to consumers and employees. Our engineering, cloud, data, experience design, and talent solution capabilities accelerate transformation and impact for enterprise clients. Headquartered in New Jersey, our workforce of 6,000+ Ascenders delivers solutions from around the globe. Ascendion is built differently to engineer the next. Ascendion | Engineering to elevate life\nWe have a culture built on opportunity, inclusion, and a spirit of partnership. Come, change the world with us:\n¬∑ Build the coolest tech for world‚Äôs leading brands\n¬∑ Solve complex problems ‚Äì and learn new skills\n¬∑ Experience the power of transforming digital engineering for Fortune 500 clients\n¬∑ Master your craft with leading training programs and hands-on experience\nExperience a community of change makers!\nJoin a culture of high-performing innovators with endless ideas and a passion for tech. Our culture is the fabric of our company, and it is what makes us unique and diverse. The way we share ideas, learning, experiences, successes, and joy allows everyone to be their best at Ascendion.\nAbout the Role:\n\n\nJob Title : Python Developer\n\nLocation: Hybrid in Toronto, Canada\n\n \n\nLooking for Python Developer with Django, Flask and FastAPI\n\n\n\nSalary Range: The salary for this position is between $130,000 ‚Äì $140,000 annually. Factors which may affect pay within this range may include geography/market, skills, education, experience, and other qualifications of the successful candidate.\n\n\nBenefits: The Company offers the following benefits for this position, subject to applicable eligibility requirements: [medical insurance] [dental insurance] [vision insurance] [401(k) retirement plan] [long-term disability insurance] [short-term disability insurance] [5 personal days accrued each calendar year. The Paid time off benefits meet the paid sick and safe time laws that pertains to the City/ State] [10-15 days of paid vacation time] [6 paid holidays and 1 floating holiday per calendar year] [Ascendion Learning Management System]\n\n\nWant to change the world? Let us know.\nTell us about your experiences, education, and ambitions. Bring your knowledge, unique viewpoint, and creativity to the table. Let‚Äôs talk!\n\n    PERSONALIZED RESUME CONTENT:\n    RESUME: Amirreza Sokhankhosh\n‚ôÇphone431-293-6515 /envel‚å¢peamirreza.skhn@gmail.com /linkedinLinkedIn /githubGitHub ·ΩãCPortfolio\nHighlight of Qualifications\n‚Ä¢ Python Development: Extensive experience in Python development using Django, Flask, and FastAPI with\ndemonstrated ability in developing modular and scalable APIs that improve backend functionality and enhance user\nengagement by 25%.\n‚Ä¢ Distributed Systems & Blockchain: Engineered advanced systems using Flask and Hyperledger Fabric, show-\ncasing a strong ability to innovate in blockchain and distributed architecture, demonstrated by significant improve-\nments in fault tolerance (62.7%) and efficiency.\n‚Ä¢ AI & Machine Learning: Strong background in implementing advanced ML models with TensorFlow and Py-\nTorch, improving system performance and achieving accuracy enhancements in predictive systems by 15%.\n‚Ä¢ Cloud & DevOps: Proficient in Docker and Kubernetes for containerized deployment, reducing setup time by\n30% and enabling scalable solutions for diverse cloud environments.\n‚Ä¢ Full-stack Development: Adept at designing full-stack solutions with React and Django, ensuring seamless API\nintegration and improved data management using PostgreSQL.\nExperience\nUniversity of Manitoba Sep 2023 ‚Äì Jul 2025\nGraduate Research Assistant Winnipeg, Manitoba, Canada\n‚Ä¢ Developed modular APIs using Flask and Express.js, supporting novel distributed AI architectures, including\nsystems using blockchain consensus mechanisms.\n‚Ä¢ Reduced communication overhead by 85.2%, improved fault tolerance by 62.7%, and enhanced energy efficiency\nthrough innovative distributed machine learning architectures.\n‚Ä¢ Implemented advanced models using TensorFlow and PyTorch, optimizing system performance and resource allo-\ncation in a cloud environment.\n‚Ä¢ Published ground-breaking research in top-tier IEEE venues, showcasing expertise in AI, blockchain, and dis-\ntributed systems.\n‚Ä¢ Led initiatives that bridged digitalengineering gaps, pioneering efficiency improvements that aligned with enterprise-\nlevel needs.\nBobo May 2024 ‚Äì Aug 2024\nFull-stack Developer Intern Winnipeg, Manitoba, Canada\n‚Ä¢ Accelerated product development by designing RESTful APIs utilizing Supabase and PostgreSQL, vastly im-\nproving backend functionality and data management.\n‚Ä¢ Automated data integration processes withPython, converting CSV data to SQL scripts, which significantly stream-\nlined database population efforts.\n‚Ä¢ Collaborated closely with front-end teams to ensure seamless full-stack integration, aligning API specifications\nwith user interface requirements efficiently.\n‚Ä¢ Contributed to Agile workflows using Atlassian tools, fostering enhanced task management, documentation, and\nteam coordination.\nUniversity of Manitoba Sep 2024 ‚Äì Jun 2025\nTeaching Assistant Winnipeg, Manitoba, Canada\n‚Ä¢ Provided academic support to over 400 students in foundational courses including Introduction to Programming\n(Python) and Data Structures Algorithms .\n‚Ä¢ Guided students in solving complex coding and theoretical challenges, emphasizingproblem-solving and algorithm\ndesign.\n‚Ä¢ Resolved programming issues in departmental Help Centre, advising on best coding practices and encouraging a\nstrong grasp of Python and other core technologies.Projects\nMini Task Manager | Django, Django REST Framework, Python, React, SQLite| Code\n‚Ä¢ Developed a secure token-based authentication system with Django REST Framework to ensure user data\nprotection and streamlined access management.\n‚Ä¢ Implemented full CRUD operations for task management using React and Django, enabling seamless client-\nserver interactions and enhancing user experience.\n‚Ä¢ Engineered a responsive Material-UI interface, improving usability across devices, which led to a 25% increase\nin user engagement.\nExplanation: 1. **Technology Selection**: Emphasized ‚ÄòDjango‚Äò, ‚ÄòDjango REST Framework‚Äò, and ‚ÄòPython‚Äò as\nthey are directly related to the job requirement. Included ‚ÄòReact‚Äò to show full-stack capabilities and ‚ÄòSQLite‚Äò as a\nrelevant technology for data persistence. 2. **Achievements and Technical Details**: Focused on authentication,\nCRUD operations, and responsive design‚Äîall essential for a Python Developer role. 3. **Impact and Metrics**:\nHighlighted user engagement improvement to provide a tangible outcome of the project work.\nFederated Learning enabled Digital Twin | Python, Flask, Hyperledger Fabric, Docker, PyTorch| Code\n‚Ä¢ Developed a privacy-preserving Digital Twin system using Flask and Hyperledger Fabric, ensuring secure and\ndecentralized management of IoT sensor data across 76 smart building rooms.\n‚Ä¢ Implemented Temporal Fusion Transformer (TFT) models in PyTorch for accurate multi-variate time-series\nforecasting of temperature, CO2, and humidity levels with a median accuracy improvement of 15%.\n‚Ä¢ Integrated Docker for containerized deployment, reducing setup time by 30% and enabling seamless scaling across\nvarious real-world IoT environments.\nProof of Collaborative Learning (PoCL) | Python, Flask, TensorFlow, Docker, Hyperledger Fabric| Code\n‚Ä¢ Developed an innovativeblockchain consensus mechanismusing Python and TensorFlowto replace traditional\nmining with federated learning, increasing energy efficiency by reducing computational load.\n‚Ä¢ Integrated Flask as an API gateway to facilitate seamless communication and coordination between miners and\nthe blockchain network, ensuring robust and scalable architecture.\n‚Ä¢ Leveraged Hyperledger Fabric and Docker to deploy a decentralised, immutable ledger that streamlined trans-\naction processing and enhanced system reliability and availability.\nPaper Summarizer | Python, Flask, Detectron2, EasyOCR, PyTorch| Code\n‚Ä¢ Implemented an end-to-end academic paper summarization system utilizing Python and Flask, enabling efficient\nand automated content comprehension.\n‚Ä¢ Utilized Detectron2 with Faster R-CNNfor precise object detection, achieving accurate identification of document\nelements, including text and figures.\n‚Ä¢ Enhanced text and figure extraction accuracy with EasyOCR and PyTorch, resulting in comprehensive and co-\nherent summaries with structured PDF output.\nEducation\nUniversity of Manitoba Sep 2023 ‚Äì Aug 2025\nMaster of Science in Computer Science (GPA: 4.4 / 4.5) Winnipeg, Canada\n‚Ä¢ Relevant Coursework: Security & Privacy, Deep Generative Modeling, Blockchain & Distributed Systems: A+\nK.N. Toosi University of Technology Sep 2018 ‚Äì Feb 2023\nBachelor of Science in Computer Engineering\nTechnical Skills\nLanguages: Python, JavaScript, TypeScript, Java, C++\nWeb Frameworks: Back-end: Django, Flask, FastAPI. Front-end: React, Express.JS\nDatabases: PostgreSQL, MongoDB, MySQL, Redis\nCloud & DevOps: Docker, Git, GitHub, Linux, CI/CD, Kubernetes\nTools & Methodologies: Jira, Confluence, Agile, Scrum\nAI / Machine Learning : TensorFlow, Keras, PyTorch, Numpy, Pandas, Scikit-learn\n\n    RETRIEVED CONTEXT FROM KNOWLEDGE BASE:\n    [Document(id=\'3325f8b5-cac8-47aa-ab0d-018c50ca37e5\', metadata={\'start_index\': 0, \'source\': \'cover letter\', \'position\': \'Python Developer\', \'company\': \'Ascendion\'}, page_content="I am excited to apply for the Python Developer position at \\\\textbf{Ascendion}. With my background in \\\\textbf{Python development} and experience in frameworks such as \\\\textbf{Django}, \\\\textbf{Flask}, and \\\\textbf{FastAPI}, I am eager to contribute to your team‚Äôs mission of transforming digital engineering and delivering captivating experiences. Ascendion\'s culture of innovation and its commitment to engineering that elevates life strongly resonate with my professional values and aspirations."), Document(id=\'15649aed-4073-49f5-807e-04fc96505ce0\', metadata={\'start_index\': 0, \'position\': \'Python Developer\', \'company\': \'Ascendion\', \'source\': \'cover letter\'}, page_content="I am excited to apply for the Python Developer position at \\\\textbf{Ascendion}. With my background in \\\\textbf{Python development} and experience in frameworks such as \\\\textbf{Django}, \\\\textbf{Flask}, and \\\\textbf{FastAPI}, I am eager to contribute to your team‚Äôs mission of transforming digital engineering and delivering captivating experiences. Ascendion\'s culture of innovation and its commitment to engineering that elevates life strongly resonate with my professional values and aspirations."), Document(id=\'c9163008-0ebe-447e-9477-80ed0da48ef6\', metadata={\'position\': \'Python Developer\', \'company\': \'Ascendion\', \'start_index\': 0, \'source\': \'cover letter\'}, page_content="I am excited to apply for the Python Developer position at \\\\textbf{Ascendion}. With my extensive experience in \\\\textbf{Python development} and proficiency in frameworks such as \\\\textbf{Django}, \\\\textbf{Flask}, and \\\\textbf{FastAPI}, I am eager to contribute to your team‚Äôs mission of transforming digital engineering and delivering captivating experiences. Ascendion\'s culture of innovation and its commitment to engineering that elevates life strongly resonate with my professional values and aspirations."), Document(id=\'9f633635-33d1-40f1-a506-22d8d27d73ba\', metadata={\'company\': \'Ascendion\', \'source\': \'cover letter\', \'position\': \'Python Developer\', \'start_index\': 0}, page_content="I am excited to apply for the Python Developer position at \\\\textbf{Ascendion}. With my extensive experience in \\\\textbf{Python development} and proficiency in frameworks such as \\\\textbf{Django}, \\\\textbf{Flask}, and \\\\textbf{FastAPI}, I am eager to contribute to your team‚Äôs mission of transforming digital engineering and delivering captivating experiences. Ascendion\'s culture of innovation and its commitment to engineering that elevates life strongly resonate with my professional values and aspirations."), Document(id=\'39fc2647-7830-4dac-9b5d-b1aba7e35b2a\', metadata={\'position\': \'Python Developer\', \'company\': \'Ascendion\', \'source\': \'cover letter\', \'start_index\': 0}, page_content="I am excited to apply for the Python Developer position at \\\\textbf{Ascendion}. With my extensive experience in \\\\textbf{Python development} and proficiency in frameworks such as \\\\textbf{Django}, \\\\textbf{Flask}, and \\\\textbf{FastAPI}, I am eager to contribute to your team‚Äôs mission of transforming digital engineering and delivering captivating experiences. Ascendion\'s culture of innovation and its commitment to engineering that elevates life strongly resonate with my professional values and aspirations."), Document(id=\'b4447976-35c8-4e28-9835-d87a11efa906\', metadata={\'start_index\': 0, \'company\': \'Ascendion\', \'source\': \'cover letter\', \'position\': \'Python Developer\'}, page_content=\'I am excited to apply for the Python Developer position at \\\\textbf{Ascendion}. With my background in \\\\textbf{Python development} and extensive experience in frameworks such as \\\\textbf{Django}, \\\\textbf{Flask}, and \\\\textbf{FastAPI}, I am eager to contribute to your team‚Äôs mission of transforming digital engineering and delivering captivating experiences.\\n\\nIn my recent projects, I have built scalable and secure applications using \\\\textbf{Python} and its frameworks, aligning with your requirements. For example, in my \\\\textbf{Mini Task Manager} project, I developed a token-based authentication system using \\\\textbf{Django REST Framework}, which resulted in a 25\\\\% increase in user engagement. Furthermore, my proficiency with \\\\textbf{Docker} and \\\\textbf{Kubernetes} has enabled me to reduce setup times by 30\\\\%, preparing me for the dynamic challenges outlined in your job posting.\'), Document(id=\'498860ac-ce95-4adc-8db4-d854f58ef15e\', metadata={\'position\': \'Python Developer\', \'start_index\': 885, \'source\': \'cover letter\', \'company\': \'Ascendion\'}, page_content="I am particularly drawn to \\\\textbf{Ascendion}\'s commitment to creating opportunities and fostering inclusion. My projects, such as the \\\\textbf{Federated Learning enabled Digital Twin}, demonstrate my ability to innovate within \\\\textbf{blockchain} and IoT, supporting \\\\textbf{Ascendion}\'s mission to engineer solutions for Fortune 500 clients. The culture of high performance and endless innovation at Ascendion resonates deeply with my professional values and aspirations.\\n\\nI am enthusiastic about the opportunity to contribute to \\\\textbf{Ascendion}\'s mission by bringing my skills to build advanced digital solutions. My background in \\\\textbf{distributed systems} and passion for \\\\textbf{digital engineering} uniquely position me to make significant contributions to your team. I am excited to bring my perspective and technical expertise to Ascendion, collaborating to create technology that elevates life."), Document(id=\'d2f30633-a110-4546-9653-bcce5f4685d0\', metadata={\'start_index\': 1025, \'company\': \'Ascendion\', \'source\': \'cover letter\', \'position\': \'Python Developer\'}, page_content="I am particularly drawn to \\\\textbf{Ascendion}\'s dedication to creating opportunities and fostering inclusion. My projects, such as the \\\\textbf{Federated Learning enabled Digital Twin}, demonstrate my ability to innovate within \\\\textbf{blockchain} and IoT, supporting \\\\textbf{Ascendion}\'s mission to engineer solutions for Fortune 500 clients. The culture of high performance and endless innovation at Ascendion resonates deeply with my professional values and aspirations.\\n\\nI am enthusiastic about the opportunity to contribute to \\\\textbf{Ascendion}\'s mission by bringing my skills to build advanced digital solutions. My background in \\\\textbf{distributed systems} and passion for \\\\textbf{digital engineering} uniquely position me to make significant contributions to your team. I am excited to bring my perspective and technical expertise to Ascendion, collaborating to create technology that elevates life.")]\n                                                       \n    INSTRUCTIONS:\n    1. Analyze the job posting to identify:\n       - Company mission, values, and culture\n       - Key technical requirements and preferred technologies\n       - Required experience level and responsibilities\n       - Specific skills and qualifications sought\n\n    2. Use the personalized resume content to:\n       - Highlight the most relevant experiences and achievements\n       - Showcase technical skills that match job requirements\n       - Reference specific projects that demonstrate required capabilities\n       - Quantify accomplishments where possible\n\n    3. Leverage the retrieved context to:\n       - Add depth and authenticity to your statements\n       - Reference relevant research, projects, or experiences not in the resume\n       - Demonstrate domain knowledge and passion for the field\n       - Show progression and learning from past experiences\n\n    4. Follow the template structure but adapt content to:\n       - Match the company\'s tone and industry language\n       - Create a narrative that connects past experiences to future contributions\n       - Show genuine enthusiasm for the specific role and company\n       - Address any potential gaps or explain career transitions\n\n\n    CRITICAL OUTPUT REQUIREMENTS:\n    - Generate ONLY the cover letter content paragraphs\n    - DO NOT include any LaTeX document structure (\\documentclass, \\begin{document}, \\begin{letter}, \\end{letter}, \\end{document})\n    - DO NOT include any explanations, introductions, or meta-commentary\n    - DO NOT include salutations like "Dear Hiring Manager" or closings like "Sincerely"\n    - Start directly with the first paragraph content\n    - End with the last paragraph content\n    - Use clean paragraph breaks (double newlines) between paragraphs\n\n    CONTENT STRUCTURE:\n    Write exactly 3-4 paragraphs of cover letter content:\n\n    Paragraph 1: Express enthusiasm for the specific role and company, briefly state your relevant background and why you\'re applying.\n\n    Paragraph 2: Highlight your most relevant technical experiences and projects with specific examples that match the job requirements.\n\n    Paragraph 3: Demonstrate alignment with the company\'s mission and technology stack, referencing retrieved context to show deeper knowledge and genuine interest.\n\n    Paragraph 4 (optional): Reiterate enthusiasm and mention specific contributions you can make to the team and company.\n\n                                                       \n    COVER LETTER STRUCTURE:\n    1. Opening paragraph: Express enthusiasm for the specific role and company, briefly state your relevant background\n    2. Body paragraph 1: Highlight relevant technical experience and projects with specific examples\n    3. Body paragraph 2: Demonstrate alignment with company mission/technology stack, reference retrieved context for depth\n    4. Closing paragraph: Reiterate enthusiasm, mention specific contributions you can make, professional closing\n\n    TONE AND STYLE:\n    - Professional yet enthusiastic\n    - Confident but not boastful\n    - Specific and detailed, not generic\n    - Forward-looking and solution-oriented\n    - Authentic and genuine\n    LATEX FORMATTING REQUIREMENTS:\n    - Use proper LaTeX escaping: \\& instead of & for ampersands\n    - Use \\% for percentages in text  \n    - Use \\textbf{} for emphasizing key technologies, company names, and achievements\n    - Write in clean, readable paragraph format\n    - Use standard paragraph separation (double newlines)\n\n    CONTENT GUIDELINES:\n    - Reference specific technologies, frameworks, and methodologies from the job posting\n    - Use metrics and quantified achievements where available\n    - Show understanding of the company\'s challenges and how you can help\n    - Demonstrate continuous learning and adaptability\n    - Connect past experiences to future potential contributions\n    - Use retrieved context to add unique insights or relevant background\n    - Be professional yet enthusiastic, confident but not boastful\n    - Make it specific and detailed, not generic\n\n    OUTPUT FORMAT EXAMPLE:\n    I am excited to apply for the {position} position at \\textbf{{company name}}. With my background in \\textbf{relevant technology} and experience in \\textbf{relevant domain}, I am eager to contribute to your team\'s mission of advancing \\textbf{company focus area}.\n\n    In my recent projects, I have built scalable applications using \\textbf{specific technologies} that align with your requirements. For example, in my \\textbf{project name} project, I developed \\textbf{specific implementation} that resulted in \\textbf{quantified outcome}. My experience with \\textbf{relevant technology stack} has prepared me to tackle the challenges outlined in your job posting.\n\n    I am particularly drawn to \\textbf{{company name}}\'s commitment to \\textbf{company values/mission}. My research in \\textbf{relevant area from context} has given me deep insights into \\textbf{relevant domain knowledge}, and I am excited about the opportunity to apply this knowledge in a production environment where I can help \\textbf{specific company goals}.\n\n    Generate the cover letter content paragraphs following this exact format:\n    ', 'role': 'user'}], 'model': 'gpt-4o', 'stream': False}}
2025-10-08 19:55:21,773 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-10-08 19:55:21,773 [DEBUG] httpcore.connection: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
2025-10-08 19:55:21,811 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x125e1d0d0>
2025-10-08 19:55:21,811 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x1242669f0> server_hostname='api.openai.com' timeout=None
2025-10-08 19:55:21,847 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x126c865d0>
2025-10-08 19:55:21,847 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-08 19:55:21,847 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-08 19:55:21,847 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-08 19:55:21,847 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-08 19:55:21,847 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-08 19:55:21,969 [DEBUG] urllib3.connectionpool: https://us.i.posthog.com:443 "POST /batch/ HTTP/1.1" 200 15
2025-10-08 19:55:43,894 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 09 Oct 2025 00:55:43 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'personal-moaon6'), (b'openai-processing-ms', b'19202'), (b'openai-project', b'proj_xpqpZ6mXeDEwLbfYGvXUcwd5'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'21914'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'24538'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'10.924s'), (b'x-request-id', b'req_320b0423c8f34e8e92b4a0c7cdf2a368'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=nF3XZNw09ncQUed1IToTadn28AhjrmDW5Laii9YmwEo-1759971343-1.0.1.1-2jft8bpc8xiSYk5r39Juv7CFjah9zB.n13tD2cyCaddWjDMbeU.TT19lvKyvRG8_eNrsyNFq33_FnydbtcW5EVLxTYPrLOTOoD2BxzCgX2M; path=/; expires=Thu, 09-Oct-25 01:25:43 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=w3IBkDlco9LGLjOI7o6A_4clQ6A35h64.U0tNvVZHoE-1759971343977-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'98b9e97a4c6aa2a1-ORD'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-10-08 19:55:43,897 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-10-08 19:55:43,897 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-08 19:55:43,905 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-08 19:55:43,905 [DEBUG] httpcore.http11: response_closed.started
2025-10-08 19:55:43,905 [DEBUG] httpcore.http11: response_closed.complete
2025-10-08 19:55:43,905 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 09 Oct 2025 00:55:43 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'personal-moaon6'), ('openai-processing-ms', '19202'), ('openai-project', 'proj_xpqpZ6mXeDEwLbfYGvXUcwd5'), ('openai-version', '2020-10-01'), ('x-envoy-upstream-service-time', '21914'), ('x-ratelimit-limit-requests', '500'), ('x-ratelimit-limit-tokens', '30000'), ('x-ratelimit-remaining-requests', '499'), ('x-ratelimit-remaining-tokens', '24538'), ('x-ratelimit-reset-requests', '120ms'), ('x-ratelimit-reset-tokens', '10.924s'), ('x-request-id', 'req_320b0423c8f34e8e92b4a0c7cdf2a368'), ('x-openai-proxy-wasm', 'v0.1'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=nF3XZNw09ncQUed1IToTadn28AhjrmDW5Laii9YmwEo-1759971343-1.0.1.1-2jft8bpc8xiSYk5r39Juv7CFjah9zB.n13tD2cyCaddWjDMbeU.TT19lvKyvRG8_eNrsyNFq33_FnydbtcW5EVLxTYPrLOTOoD2BxzCgX2M; path=/; expires=Thu, 09-Oct-25 01:25:43 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=w3IBkDlco9LGLjOI7o6A_4clQ6A35h64.U0tNvVZHoE-1759971343977-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '98b9e97a4c6aa2a1-ORD'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-10-08 19:55:43,905 [DEBUG] openai._base_client: request_id: req_320b0423c8f34e8e92b4a0c7cdf2a368
2025-10-08 19:55:45,372 [INFO] chromadb.telemetry.product.posthog: Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-10-08 19:55:45,378 [DEBUG] chromadb.config: Starting component System
2025-10-08 19:55:45,378 [DEBUG] chromadb.config: Starting component Posthog
2025-10-08 19:55:45,378 [DEBUG] chromadb.config: Starting component OpenTelemetryClient
2025-10-08 19:55:45,378 [DEBUG] chromadb.config: Starting component FastAPI
2025-10-08 19:55:45,379 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=8000 local_address=None timeout=None socket_options=None
2025-10-08 19:55:45,383 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x126521b50>
2025-10-08 19:55:45,384 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-08 19:55:45,384 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-08 19:55:45,384 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-08 19:55:45,384 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-08 19:55:45,384 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-08 19:55:45,385 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'content-type', b'application/json'), (b'content-length', b'73'), (b'date', b'Thu, 09 Oct 2025 00:55:45 GMT')])
2025-10-08 19:55:45,385 [INFO] httpx: HTTP Request: GET http://localhost:8000/api/v2/auth/identity "HTTP/1.1 200 OK"
2025-10-08 19:55:45,385 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-08 19:55:45,385 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-08 19:55:45,385 [DEBUG] httpcore.http11: response_closed.started
2025-10-08 19:55:45,385 [DEBUG] httpcore.http11: response_closed.complete
2025-10-08 19:55:45,385 [INFO] chromadb.telemetry.product.posthog: Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-10-08 19:55:45,392 [DEBUG] chromadb.config: Starting component System
2025-10-08 19:55:45,392 [DEBUG] chromadb.config: Starting component Posthog
2025-10-08 19:55:45,392 [DEBUG] chromadb.config: Starting component OpenTelemetryClient
2025-10-08 19:55:45,392 [DEBUG] chromadb.config: Starting component FastAPI
2025-10-08 19:55:45,392 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=8000 local_address=None timeout=None socket_options=None
2025-10-08 19:55:45,395 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x12652c090>
2025-10-08 19:55:45,395 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-08 19:55:45,395 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-08 19:55:45,395 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-08 19:55:45,395 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-08 19:55:45,395 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-08 19:55:45,396 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'content-type', b'application/json'), (b'content-length', b'46'), (b'date', b'Thu, 09 Oct 2025 00:55:45 GMT')])
2025-10-08 19:55:45,396 [INFO] httpx: HTTP Request: GET http://localhost:8000/api/v2/tenants/default_tenant "HTTP/1.1 200 OK"
2025-10-08 19:55:45,396 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-08 19:55:45,396 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-08 19:55:45,396 [DEBUG] httpcore.http11: response_closed.started
2025-10-08 19:55:45,396 [DEBUG] httpcore.http11: response_closed.complete
2025-10-08 19:55:45,396 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-08 19:55:45,396 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-08 19:55:45,396 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-08 19:55:45,396 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-08 19:55:45,397 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-08 19:55:45,397 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'content-type', b'application/json'), (b'content-length', b'97'), (b'date', b'Thu, 09 Oct 2025 00:55:45 GMT')])
2025-10-08 19:55:45,397 [INFO] httpx: HTTP Request: GET http://localhost:8000/api/v2/tenants/default_tenant/databases/default_database "HTTP/1.1 200 OK"
2025-10-08 19:55:45,397 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-08 19:55:45,397 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-08 19:55:45,397 [DEBUG] httpcore.http11: response_closed.started
2025-10-08 19:55:45,397 [DEBUG] httpcore.http11: response_closed.complete
2025-10-08 19:55:45,399 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-08 19:55:45,399 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-08 19:55:45,399 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-08 19:55:45,399 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-08 19:55:45,399 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-08 19:55:45,400 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'content-type', b'application/json'), (b'content-length', b'363'), (b'date', b'Thu, 09 Oct 2025 00:55:45 GMT')])
2025-10-08 19:55:45,400 [INFO] httpx: HTTP Request: POST http://localhost:8000/api/v2/tenants/default_tenant/databases/default_database/collections "HTTP/1.1 200 OK"
2025-10-08 19:55:45,400 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-08 19:55:45,400 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-08 19:55:45,401 [DEBUG] httpcore.http11: response_closed.started
2025-10-08 19:55:45,401 [DEBUG] httpcore.http11: response_closed.complete
2025-10-08 19:55:45,403 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'idempotency_key': 'stainless-python-retry-a463d2d3-8f21-4c21-8f40-adbff688d5ee', 'post_parser': <function Embeddings.create.<locals>.parser at 0x110e8dbc0>, 'json_data': {'input': [[40, 1097, 12304, 311, 3881, 369, 279, 13325, 25922, 2361, 520, 1144, 1342, 13536, 90, 41203, 408, 290, 7966, 3161, 856, 4092, 304, 1144, 1342, 13536, 90, 31380, 4500, 92, 323, 16781, 3217, 449, 49125, 1778, 439, 1144, 1342, 13536, 90, 35, 5970, 2186, 1144, 1342, 13536, 90, 3968, 1091, 2186, 323, 1144, 1342, 13536, 90, 33274, 7227, 2186, 358, 1097, 24450, 311, 17210, 311, 701, 2128, 596, 9131, 315, 46890, 7528, 15009, 323, 24944, 86282, 11704, 13, 40660, 408, 290, 596, 7829, 315, 19297, 323, 1202, 39955, 311, 15009, 430, 12231, 988, 2324, 16917, 89986, 449, 856, 6721, 2819, 323, 58522, 13], [644, 856, 3293, 7224, 11, 358, 617, 5918, 69311, 323, 9966, 8522, 1701, 1144, 1342, 13536, 90, 31380, 92, 323, 1202, 49125, 11, 5398, 287, 449, 701, 8670, 13, 1789, 3187, 11, 304, 856, 1144, 1342, 13536, 90, 55313, 5546, 10790, 92, 2447, 11, 358, 8040, 264, 4037, 6108, 17066, 1887, 1701, 1144, 1342, 13536, 90, 35, 5970, 26487, 24686, 2186, 13239, 304, 264, 220, 914, 59, 4, 5376, 304, 1217, 20392, 13, 24296, 11, 856, 63239, 449, 1144, 1342, 13536, 90, 35, 13973, 92, 323, 1144, 1342, 13536, 90, 42, 30927, 92, 706, 9147, 757, 311, 8108, 6642, 3115, 555, 220, 966, 59, 13689, 20646, 757, 369, 279, 8915, 11774, 33740, 304, 701, 2683, 17437, 382, 40, 1097, 8104, 15107, 311, 1144, 1342, 13536, 90, 41203, 408, 290, 11923, 82, 15507, 311, 6968, 10708, 323, 86644, 28286, 13, 3092, 7224, 11, 1778, 439, 279, 1144, 1342, 13536, 90, 37, 7442, 660, 21579, 9147, 14434, 36047, 2186, 20461, 856, 5845, 311, 92064, 2949, 1144, 1342, 13536, 90, 4677, 8995, 92, 323, 50180, 11, 12899, 40660, 408, 290, 596, 9131, 311, 24490, 10105, 369, 46331, 220, 2636, 8403, 13, 578, 7829, 315, 1579, 5178, 323, 26762, 19297, 520, 40660, 408, 290, 29280, 988, 17693, 449, 856, 6721, 2819, 323, 58522, 13], [40, 1097, 42702, 922, 279, 6776, 311, 17210, 311, 1144, 1342, 13536, 90, 41203, 408, 290, 11923, 82, 9131, 555, 12967, 856, 7512, 311, 1977, 11084, 7528, 10105, 13, 3092, 4092, 304, 1144, 1342, 13536, 90, 63475, 6067, 92, 323, 11939, 369, 1144, 1342, 13536, 90, 58369, 15009, 92, 42329, 2361, 757, 311, 1304, 5199, 19564, 311, 701, 2128, 13, 358, 1097, 12304, 311, 4546, 856, 13356, 323, 11156, 19248, 311, 40660, 408, 290, 11, 73301, 311, 1893, 5557, 430, 12231, 988, 2324, 13]], 'model': 'text-embedding-3-large', 'encoding_format': 'base64'}}
2025-10-08 19:55:45,403 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2025-10-08 19:55:45,403 [DEBUG] httpcore.connection: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
2025-10-08 19:55:45,436 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x126530ed0>
2025-10-08 19:55:45,436 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x125a82ba0> server_hostname='api.openai.com' timeout=None
2025-10-08 19:55:45,478 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x126530f90>
2025-10-08 19:55:45,478 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-08 19:55:45,478 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-08 19:55:45,478 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-08 19:55:45,478 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-08 19:55:45,478 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-08 19:55:45,706 [DEBUG] urllib3.connectionpool: https://us.i.posthog.com:443 "POST /batch/ HTTP/1.1" 200 15
2025-10-08 19:55:45,731 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 09 Oct 2025 00:55:45 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-large'), (b'openai-organization', b'personal-moaon6'), (b'openai-processing-ms', b'131'), (b'openai-project', b'proj_xpqpZ6mXeDEwLbfYGvXUcwd5'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-canary-794cf74f59-hcs9d'), (b'x-envoy-upstream-service-time', b'174'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999603'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'23ms'), (b'x-request-id', b'req_47f7a0b015cb48799b3c30424f875c76'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=XvQmt_jq6oR6WVY.DfC90paKMfnOKyS0dhd65F_csFk-1759971345-1.0.1.1-EXbgIrFoF41QCeYwJOA.5EymemlXwOfMJttSbjGNSY2AyclcmsPhtACpvxnEzUaJreBM9mxE6PkEr6bv34MLP2IQPJ.prDAG_o5vGM6Tf1c; path=/; expires=Thu, 09-Oct-25 01:25:45 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=hJGP6IZCwlcoOrZ17iJubE.rH476l0PdnN4rS0PrPxs-1759971345813-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'98b9ea0dffb2618b-ORD'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-10-08 19:55:45,731 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-10-08 19:55:45,731 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-08 19:55:45,737 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-08 19:55:45,737 [DEBUG] httpcore.http11: response_closed.started
2025-10-08 19:55:45,737 [DEBUG] httpcore.http11: response_closed.complete
2025-10-08 19:55:45,737 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers([('date', 'Thu, 09 Oct 2025 00:55:45 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-allow-origin', '*'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-model', 'text-embedding-3-large'), ('openai-organization', 'personal-moaon6'), ('openai-processing-ms', '131'), ('openai-project', 'proj_xpqpZ6mXeDEwLbfYGvXUcwd5'), ('openai-version', '2020-10-01'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('via', 'envoy-router-canary-794cf74f59-hcs9d'), ('x-envoy-upstream-service-time', '174'), ('x-ratelimit-limit-requests', '3000'), ('x-ratelimit-limit-tokens', '1000000'), ('x-ratelimit-remaining-requests', '2999'), ('x-ratelimit-remaining-tokens', '999603'), ('x-ratelimit-reset-requests', '20ms'), ('x-ratelimit-reset-tokens', '23ms'), ('x-request-id', 'req_47f7a0b015cb48799b3c30424f875c76'), ('x-openai-proxy-wasm', 'v0.1'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=XvQmt_jq6oR6WVY.DfC90paKMfnOKyS0dhd65F_csFk-1759971345-1.0.1.1-EXbgIrFoF41QCeYwJOA.5EymemlXwOfMJttSbjGNSY2AyclcmsPhtACpvxnEzUaJreBM9mxE6PkEr6bv34MLP2IQPJ.prDAG_o5vGM6Tf1c; path=/; expires=Thu, 09-Oct-25 01:25:45 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=hJGP6IZCwlcoOrZ17iJubE.rH476l0PdnN4rS0PrPxs-1759971345813-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '98b9ea0dffb2618b-ORD'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-10-08 19:55:45,737 [DEBUG] openai._base_client: request_id: req_47f7a0b015cb48799b3c30424f875c76
2025-10-08 19:55:45,739 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-08 19:55:45,739 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-08 19:55:45,739 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-08 19:55:45,739 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-08 19:55:45,739 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-08 19:55:45,739 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'content-type', b'application/json'), (b'content-length', b'55'), (b'date', b'Thu, 09 Oct 2025 00:55:45 GMT')])
2025-10-08 19:55:45,739 [INFO] httpx: HTTP Request: GET http://localhost:8000/api/v2/pre-flight-checks "HTTP/1.1 200 OK"
2025-10-08 19:55:45,740 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-08 19:55:45,741 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-08 19:55:45,741 [DEBUG] httpcore.http11: response_closed.started
2025-10-08 19:55:45,741 [DEBUG] httpcore.http11: response_closed.complete
2025-10-08 19:55:45,741 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-08 19:55:45,742 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-08 19:55:45,742 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-08 19:55:45,742 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-08 19:55:45,742 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-08 19:55:45,790 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'content-type', b'application/json'), (b'content-length', b'2'), (b'date', b'Thu, 09 Oct 2025 00:55:45 GMT')])
2025-10-08 19:55:45,790 [INFO] httpx: HTTP Request: POST http://localhost:8000/api/v2/tenants/default_tenant/databases/default_database/collections/87760c6d-637c-45d3-bbc4-b592e9ab0264/upsert "HTTP/1.1 200 OK"
2025-10-08 19:55:45,790 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-08 19:55:45,790 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-08 19:55:45,790 [DEBUG] httpcore.http11: response_closed.started
2025-10-08 19:55:45,790 [DEBUG] httpcore.http11: response_closed.complete
2025-10-08 19:55:45,824 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'idempotency_key': 'stainless-python-retry-6da6f913-9c85-4bc3-9607-84b53043f2e4', 'post_parser': <function Embeddings.create.<locals>.parser at 0x122d44c20>, 'json_data': {'input': 'Company: Ascendion. Position: Python Developer. Description: About the job\nAbout Ascendion\nAscendion is a full-service digital engineering solutions company. We make and manage software platforms and products that power growth and deliver captivating experiences to consumers and employees. Our engineering, cloud, data, experience design, and talent solution capabilities accelerate transformation and impact for enterprise clients. Headquartered in New Jersey, our workforce of 6,000+ Ascenders delivers solutions from around the globe. Ascendion is built differently to engineer the next. Ascendion | Engineering to elevate life\nWe have a culture built on opportunity, inclusion, and a spirit of partnership. Come, change the world with us:\n¬∑ Build the coolest tech for world‚Äôs leading brands\n¬∑ Solve complex problems ‚Äì and learn new skills\n¬∑ Experience the power of transforming digital engineering for Fortune 500 clients\n¬∑ Master your craft with leading training programs and hands-on experience\nExperience a community of change makers!\nJoin a culture of high-performing innovators with endless ideas and a passion for tech. Our culture is the fabric of our company, and it is what makes us unique and diverse. The way we share ideas, learning, experiences, successes, and joy allows everyone to be their best at Ascendion.\nAbout the Role:\n\n\nJob Title : Python Developer\n\nLocation: Hybrid in Toronto, Canada\n\n \n\nLooking for Python Developer with Django, Flask and FastAPI\n\n\n\nSalary Range: The salary for this position is between $130,000 ‚Äì $140,000 annually. Factors which may affect pay within this range may include geography/market, skills, education, experience, and other qualifications of the successful candidate.\n\n\nBenefits: The Company offers the following benefits for this position, subject to applicable eligibility requirements: [medical insurance] [dental insurance] [vision insurance] [401(k) retirement plan] [long-term disability insurance] [short-term disability insurance] [5 personal days accrued each calendar year. The Paid time off benefits meet the paid sick and safe time laws that pertains to the City/ State] [10-15 days of paid vacation time] [6 paid holidays and 1 floating holiday per calendar year] [Ascendion Learning Management System]\n\n\nWant to change the world? Let us know.\nTell us about your experiences, education, and ambitions. Bring your knowledge, unique viewpoint, and creativity to the table. Let‚Äôs talk!', 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}
2025-10-08 19:55:45,824 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2025-10-08 19:55:45,825 [DEBUG] httpcore.connection: close.started
2025-10-08 19:55:45,825 [DEBUG] httpcore.connection: close.complete
2025-10-08 19:55:45,825 [DEBUG] httpcore.connection: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-10-08 19:55:45,858 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x12652d450>
2025-10-08 19:55:45,858 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x11224f260> server_hostname='api.openai.com' timeout=5.0
2025-10-08 19:55:45,895 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x12652cfd0>
2025-10-08 19:55:45,896 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-08 19:55:45,896 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-08 19:55:45,896 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-08 19:55:45,896 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-08 19:55:45,896 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-08 19:55:46,186 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 09 Oct 2025 00:55:46 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'personal-moaon6'), (b'openai-processing-ms', b'62'), (b'openai-project', b'proj_xpqpZ6mXeDEwLbfYGvXUcwd5'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-76f88f4767-sj5mg'), (b'x-envoy-upstream-service-time', b'201'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999384'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'36ms'), (b'x-request-id', b'req_d56a30f41d164cdb89ab1cf89a38fc2c'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'98b9ea109e784848-ORD'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-10-08 19:55:46,186 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-10-08 19:55:46,187 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-08 19:55:46,187 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-08 19:55:46,187 [DEBUG] httpcore.http11: response_closed.started
2025-10-08 19:55:46,187 [DEBUG] httpcore.http11: response_closed.complete
2025-10-08 19:55:46,187 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers({'date': 'Thu, 09 Oct 2025 00:55:46 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-3-small', 'openai-organization': 'personal-moaon6', 'openai-processing-ms': '62', 'openai-project': 'proj_xpqpZ6mXeDEwLbfYGvXUcwd5', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'via': 'envoy-router-76f88f4767-sj5mg', 'x-envoy-upstream-service-time': '201', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '1000000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '999384', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '36ms', 'x-request-id': 'req_d56a30f41d164cdb89ab1cf89a38fc2c', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '98b9ea109e784848-ORD', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-10-08 19:55:46,187 [DEBUG] openai._base_client: request_id: req_d56a30f41d164cdb89ab1cf89a38fc2c
2025-10-08 19:55:46,209 [INFO] src.api.app: ‚úÖ POST /api/generate/cover-letter/ - 200 - 25.629s
2025-10-08 19:55:46,209 [WARNING] src.api.app: üêå Slow request: POST /api/generate/cover-letter/ took 25.629s
2025-10-08 19:55:46,210 [INFO] werkzeug: 127.0.0.1 - - [08/Oct/2025 19:55:46] "POST /api/generate/cover-letter/ HTTP/1.1" 200 -
2025-10-08 19:58:38,873 [INFO] werkzeug:  * Detected change in '/Users/amirrezasokhankhosh/Documents/Workstation/Aria/agent/src/api/routes/context.py', reloading
2025-10-08 19:58:39,031 [DEBUG] httpcore.connection: close.started
2025-10-08 19:58:39,032 [DEBUG] httpcore.connection: close.complete
2025-10-08 19:58:39,032 [DEBUG] httpcore.connection: close.started
2025-10-08 19:58:39,032 [DEBUG] httpcore.connection: close.complete
2025-10-08 19:58:39,108 [DEBUG] httpcore.connection: close.started
2025-10-08 19:58:39,109 [DEBUG] httpcore.connection: close.complete
2025-10-08 19:58:39,376 [INFO] werkzeug:  * Restarting with stat
2025-10-08 19:58:41,057 [WARNING] werkzeug:  * Debugger is active!
2025-10-08 19:58:41,067 [INFO] werkzeug:  * Debugger PIN: 246-503-739
2025-10-08 19:58:43,097 [INFO] werkzeug:  * Detected change in '/Users/amirrezasokhankhosh/Documents/Workstation/Aria/agent/server.py', reloading
2025-10-08 19:58:43,320 [INFO] werkzeug:  * Restarting with stat
2025-10-08 19:58:44,373 [WARNING] werkzeug:  * Debugger is active!
2025-10-08 19:58:44,383 [INFO] werkzeug:  * Debugger PIN: 246-503-739
2025-10-08 19:59:02,579 [INFO] werkzeug:  * Detected change in '/Users/amirrezasokhankhosh/Documents/Workstation/Aria/agent/server.py', reloading
2025-10-08 19:59:02,749 [INFO] werkzeug:  * Restarting with stat
2025-10-08 20:21:40,897 [INFO] werkzeug: [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://localhost:8080
2025-10-08 20:21:40,897 [INFO] werkzeug: [33mPress CTRL+C to quit[0m
2025-10-08 20:21:40,898 [INFO] werkzeug:  * Restarting with stat
2025-10-08 20:21:41,841 [WARNING] werkzeug:  * Debugger is active!
2025-10-08 20:21:41,851 [INFO] werkzeug:  * Debugger PIN: 246-503-739
2025-10-08 20:22:29,786 [INFO] src.api.app: üåê OPTIONS /api/generate/cover-letter/ - 127.0.0.1
2025-10-08 20:22:29,787 [INFO] src.api.app: ‚úÖ OPTIONS /api/generate/cover-letter/ - 200 - 0.001s
2025-10-08 20:22:29,788 [INFO] werkzeug: 127.0.0.1 - - [08/Oct/2025 20:22:29] "OPTIONS /api/generate/cover-letter/ HTTP/1.1" 200 -
2025-10-08 20:22:29,792 [INFO] src.api.app: üåê POST /api/generate/cover-letter/ - 127.0.0.1
2025-10-08 20:22:29,793 [DEBUG] src.api.app: üìù Request data: {'jobDescription': 'About the job\nAbout Ascendion\nAscendion is a full-service digital engineering solutions company. We make and manage software platforms and products that power growth and deliver captivating experiences to consumers and employees. Our engineering, cloud, data, experience design, and talent solution capabilities accelerate transformation and impact for enterprise clients. Headquartered in New Jersey, our workforce of 6,000+ Ascenders delivers solutions from around the globe. Ascendion is built differently to engineer the next. Ascendion | Engineering to elevate life\nWe have a culture built on opportunity, inclusion, and a spirit of partnership. Come, change the world with us:\n¬∑ Build the coolest tech for world‚Äôs leading brands\n¬∑ Solve complex problems ‚Äì and learn new skills\n¬∑ Experience the power of transforming digital engineering for Fortune 500 clients\n¬∑ Master your craft with leading training programs and hands-on experience\nExperience a community of change makers!\nJoin a culture of high-performing innovators with endless ideas and a passion for tech. Our culture is the fabric of our company, and it is what makes us unique and diverse. The way we share ideas, learning, experiences, successes, and joy allows everyone to be their best at Ascendion.\nAbout the Role:\n\n\nJob Title : Python Developer\n\nLocation: Hybrid in Toronto, Canada\n\n \n\nLooking for Python Developer with Django, Flask and FastAPI\n\n\n\nSalary Range: The salary for this position is between $130,000 ‚Äì $140,000 annually. Factors which may affect pay within this range may include geography/market, skills, education, experience, and other qualifications of the successful candidate.\n\n\nBenefits: The Company offers the following benefits for this position, subject to applicable eligibility requirements: [medical insurance] [dental insurance] [vision insurance] [401(k) retirement plan] [long-term disability insurance] [short-term disability insurance] [5 personal days accrued each calendar year. The Paid time off benefits meet the paid sick and safe time laws that pertains to the City/ State] [10-15 days of paid vacation time] [6 paid holidays and 1 floating holiday per calendar year] [Ascendion Learning Management System]\n\n\nWant to change the world? Let us know.\nTell us about your experiences, education, and ambitions. Bring your knowledge, unique viewpoint, and creativity to the table. Let‚Äôs talk!', 'companyName': 'Ascendion', 'positionTitle': 'Python Developer', 'resumePdfFile': 'http://localhost:8080/api/resumes/preview/ml-engineering'}
2025-10-08 20:22:30,080 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'idempotency_key': 'stainless-python-retry-a11f62cb-1778-4c5b-a4be-f4e4753a7dff', 'post_parser': <function Embeddings.create.<locals>.parser at 0x117bfc860>, 'json_data': {'input': 'Company: Ascendion. Position: Python Developer. Description: About the job\nAbout Ascendion\nAscendion is a full-service digital engineering solutions company. We make and manage software platforms and products that power growth and deliver captivating experiences to consumers and employees. Our engineering, cloud, data, experience design, and talent solution capabilities accelerate transformation and impact for enterprise clients. Headquartered in New Jersey, our workforce of 6,000+ Ascenders delivers solutions from around the globe. Ascendion is built differently to engineer the next. Ascendion | Engineering to elevate life\nWe have a culture built on opportunity, inclusion, and a spirit of partnership. Come, change the world with us:\n¬∑ Build the coolest tech for world‚Äôs leading brands\n¬∑ Solve complex problems ‚Äì and learn new skills\n¬∑ Experience the power of transforming digital engineering for Fortune 500 clients\n¬∑ Master your craft with leading training programs and hands-on experience\nExperience a community of change makers!\nJoin a culture of high-performing innovators with endless ideas and a passion for tech. Our culture is the fabric of our company, and it is what makes us unique and diverse. The way we share ideas, learning, experiences, successes, and joy allows everyone to be their best at Ascendion.\nAbout the Role:\n\n\nJob Title : Python Developer\n\nLocation: Hybrid in Toronto, Canada\n\n \n\nLooking for Python Developer with Django, Flask and FastAPI\n\n\n\nSalary Range: The salary for this position is between $130,000 ‚Äì $140,000 annually. Factors which may affect pay within this range may include geography/market, skills, education, experience, and other qualifications of the successful candidate.\n\n\nBenefits: The Company offers the following benefits for this position, subject to applicable eligibility requirements: [medical insurance] [dental insurance] [vision insurance] [401(k) retirement plan] [long-term disability insurance] [short-term disability insurance] [5 personal days accrued each calendar year. The Paid time off benefits meet the paid sick and safe time laws that pertains to the City/ State] [10-15 days of paid vacation time] [6 paid holidays and 1 floating holiday per calendar year] [Ascendion Learning Management System]\n\n\nWant to change the world? Let us know.\nTell us about your experiences, education, and ambitions. Bring your knowledge, unique viewpoint, and creativity to the table. Let‚Äôs talk!', 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}
2025-10-08 20:22:30,101 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2025-10-08 20:22:30,102 [DEBUG] httpcore.connection: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-10-08 20:22:30,208 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x121e98250>
2025-10-08 20:22:30,209 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x107dff2f0> server_hostname='api.openai.com' timeout=5.0
2025-10-08 20:22:30,247 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x11736ec50>
2025-10-08 20:22:30,247 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-08 20:22:30,247 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-08 20:22:30,247 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-08 20:22:30,247 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-08 20:22:30,247 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-08 20:22:30,638 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 09 Oct 2025 01:22:30 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'personal-moaon6'), (b'openai-processing-ms', b'104'), (b'openai-project', b'proj_xpqpZ6mXeDEwLbfYGvXUcwd5'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-76f88f4767-sj5mg'), (b'x-envoy-upstream-service-time', b'245'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999384'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'36ms'), (b'x-request-id', b'req_56aaa63d7f6a4b67a14fd13db7563926'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=a9xQ1DTt3hoBSD1JnrhrojdJsUy025X5udt.97ybVJU-1759972950-1.0.1.1-736ivUunLC4ibUp7.mN1_3H5Tb8SNuBqV6z6guHWAYSFJEKbu6EiQkCZaRPOokwdutzUURAD4XZEmSPkqxgEmCkNjUVEulEprxIj9Avmk.k; path=/; expires=Thu, 09-Oct-25 01:52:30 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=OT3QznwgkWx8OSa3SMOVCGyWRpG2cENu7L69rIE0IhY-1759972950636-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'98ba113bbc68eadb-ORD'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-10-08 20:22:30,642 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-10-08 20:22:30,643 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-08 20:22:30,646 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-08 20:22:30,646 [DEBUG] httpcore.http11: response_closed.started
2025-10-08 20:22:30,646 [DEBUG] httpcore.http11: response_closed.complete
2025-10-08 20:22:30,647 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers([('date', 'Thu, 09 Oct 2025 01:22:30 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-allow-origin', '*'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-model', 'text-embedding-3-small'), ('openai-organization', 'personal-moaon6'), ('openai-processing-ms', '104'), ('openai-project', 'proj_xpqpZ6mXeDEwLbfYGvXUcwd5'), ('openai-version', '2020-10-01'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('via', 'envoy-router-76f88f4767-sj5mg'), ('x-envoy-upstream-service-time', '245'), ('x-ratelimit-limit-requests', '3000'), ('x-ratelimit-limit-tokens', '1000000'), ('x-ratelimit-remaining-requests', '2999'), ('x-ratelimit-remaining-tokens', '999384'), ('x-ratelimit-reset-requests', '20ms'), ('x-ratelimit-reset-tokens', '36ms'), ('x-request-id', 'req_56aaa63d7f6a4b67a14fd13db7563926'), ('x-openai-proxy-wasm', 'v0.1'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=a9xQ1DTt3hoBSD1JnrhrojdJsUy025X5udt.97ybVJU-1759972950-1.0.1.1-736ivUunLC4ibUp7.mN1_3H5Tb8SNuBqV6z6guHWAYSFJEKbu6EiQkCZaRPOokwdutzUURAD4XZEmSPkqxgEmCkNjUVEulEprxIj9Avmk.k; path=/; expires=Thu, 09-Oct-25 01:52:30 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=OT3QznwgkWx8OSa3SMOVCGyWRpG2cENu7L69rIE0IhY-1759972950636-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '98ba113bbc68eadb-ORD'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-10-08 20:22:30,647 [DEBUG] openai._base_client: request_id: req_56aaa63d7f6a4b67a14fd13db7563926
2025-10-08 20:22:30,779 [INFO] chromadb.telemetry.product.posthog: Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-10-08 20:22:30,805 [DEBUG] chromadb.config: Starting component System
2025-10-08 20:22:30,805 [DEBUG] chromadb.config: Starting component Posthog
2025-10-08 20:22:30,805 [DEBUG] chromadb.config: Starting component OpenTelemetryClient
2025-10-08 20:22:30,805 [DEBUG] chromadb.config: Starting component FastAPI
2025-10-08 20:22:30,806 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=8000 local_address=None timeout=None socket_options=None
2025-10-08 20:22:30,809 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x121f0ce90>
2025-10-08 20:22:30,809 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-08 20:22:30,809 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-08 20:22:30,809 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-08 20:22:30,809 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-08 20:22:30,809 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-08 20:22:30,822 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'content-type', b'application/json'), (b'content-length', b'73'), (b'date', b'Thu, 09 Oct 2025 01:22:30 GMT')])
2025-10-08 20:22:30,822 [INFO] httpx: HTTP Request: GET http://localhost:8000/api/v2/auth/identity "HTTP/1.1 200 OK"
2025-10-08 20:22:30,822 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-08 20:22:30,823 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-08 20:22:30,823 [DEBUG] httpcore.http11: response_closed.started
2025-10-08 20:22:30,823 [DEBUG] httpcore.http11: response_closed.complete
2025-10-08 20:22:30,824 [INFO] chromadb.telemetry.product.posthog: Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-10-08 20:22:30,829 [DEBUG] chromadb.config: Starting component System
2025-10-08 20:22:30,830 [DEBUG] chromadb.config: Starting component Posthog
2025-10-08 20:22:30,830 [DEBUG] chromadb.config: Starting component OpenTelemetryClient
2025-10-08 20:22:30,830 [DEBUG] chromadb.config: Starting component FastAPI
2025-10-08 20:22:30,830 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=8000 local_address=None timeout=None socket_options=None
2025-10-08 20:22:30,834 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1236284d0>
2025-10-08 20:22:30,834 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-08 20:22:30,834 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-08 20:22:30,834 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-08 20:22:30,834 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-08 20:22:30,834 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-08 20:22:30,844 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'content-type', b'application/json'), (b'content-length', b'46'), (b'date', b'Thu, 09 Oct 2025 01:22:30 GMT')])
2025-10-08 20:22:30,844 [INFO] httpx: HTTP Request: GET http://localhost:8000/api/v2/tenants/default_tenant "HTTP/1.1 200 OK"
2025-10-08 20:22:30,844 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-08 20:22:30,844 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-08 20:22:30,844 [DEBUG] httpcore.http11: response_closed.started
2025-10-08 20:22:30,844 [DEBUG] httpcore.http11: response_closed.complete
2025-10-08 20:22:30,844 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-08 20:22:30,845 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-08 20:22:30,845 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-08 20:22:30,845 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-08 20:22:30,845 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-08 20:22:30,846 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'content-type', b'application/json'), (b'content-length', b'97'), (b'date', b'Thu, 09 Oct 2025 01:22:30 GMT')])
2025-10-08 20:22:30,846 [INFO] httpx: HTTP Request: GET http://localhost:8000/api/v2/tenants/default_tenant/databases/default_database "HTTP/1.1 200 OK"
2025-10-08 20:22:30,846 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-08 20:22:30,846 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-08 20:22:30,846 [DEBUG] httpcore.http11: response_closed.started
2025-10-08 20:22:30,846 [DEBUG] httpcore.http11: response_closed.complete
2025-10-08 20:22:30,847 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-08 20:22:30,847 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-08 20:22:30,847 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-08 20:22:30,847 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-08 20:22:30,847 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-08 20:22:30,854 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'content-type', b'application/json'), (b'content-length', b'363'), (b'date', b'Thu, 09 Oct 2025 01:22:30 GMT')])
2025-10-08 20:22:30,854 [INFO] httpx: HTTP Request: POST http://localhost:8000/api/v2/tenants/default_tenant/databases/default_database/collections "HTTP/1.1 200 OK"
2025-10-08 20:22:30,854 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-08 20:22:30,854 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-08 20:22:30,854 [DEBUG] httpcore.http11: response_closed.started
2025-10-08 20:22:30,854 [DEBUG] httpcore.http11: response_closed.complete
2025-10-08 20:22:30,936 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'idempotency_key': 'stainless-python-retry-3ca4e9e1-0a59-483d-b6bd-42f45acecc53', 'post_parser': <function Embeddings.create.<locals>.parser at 0x121ffb1a0>, 'json_data': {'input': [[10714, 279, 2683, 198, 10714, 40660, 408, 290, 198, 41203, 408, 290, 374, 264, 2539, 24358, 7528, 15009, 10105, 2883, 13, 1226, 1304, 323, 10299, 3241, 15771, 323, 3956, 430, 2410, 6650, 323, 6493, 86282, 11704, 311, 13723, 323, 8420, 13, 5751, 15009, 11, 9624, 11, 828, 11, 3217, 2955, 11, 323, 11005, 6425, 17357, 43880, 18475, 323, 5536, 369, 20790, 8403, 13, 11452, 68720, 304, 1561, 16228, 11, 1057, 32027, 315, 220, 21, 11, 931, 10, 40660, 14846, 28421, 10105, 505, 2212, 279, 24867, 13, 40660, 408, 290, 374, 5918, 1422, 2883, 25, 40660, 408, 290, 2361, 25, 13325, 25922]], 'model': 'text-embedding-3-large', 'encoding_format': 'base64'}}
2025-10-08 20:22:30,937 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2025-10-08 20:22:30,937 [DEBUG] httpcore.connection: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
2025-10-08 20:22:30,968 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x12362bd10>
2025-10-08 20:22:30,968 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x121b62d50> server_hostname='api.openai.com' timeout=None
2025-10-08 20:22:31,008 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x121ecb510>
2025-10-08 20:22:31,008 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-08 20:22:31,008 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-08 20:22:31,008 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-08 20:22:31,008 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-08 20:22:31,008 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-08 20:22:31,304 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 09 Oct 2025 01:22:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-large'), (b'openai-organization', b'personal-moaon6'), (b'openai-processing-ms', b'65'), (b'openai-project', b'proj_xpqpZ6mXeDEwLbfYGvXUcwd5'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-797b6d7f75-b95mq'), (b'x-envoy-upstream-service-time', b'198'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999899'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'6ms'), (b'x-request-id', b'req_f6d5f92b404241058d16cab95ce4b45e'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=K0MuFD0CWLR1p4hXpvXa1UqYrEDjX6f2YZ3Wzgm6QOw-1759972951-1.0.1.1-d4r9oD578RLy_Xc.GApyWW30QIcxJ.wB9EoQqLyUMiqPwT3nk4paSFBWs6ZCTbNJmtBeGxs1ghfAuj7RmiamWz.mAkgn3mH4ZTiytOV..jc; path=/; expires=Thu, 09-Oct-25 01:52:31 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=8JAjylMJTus3jobYAVfR7NrwWOx4LAxLUgcU0Lof_gY-1759972951375-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'98ba114078a2f4ae-ORD'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-10-08 20:22:31,305 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-10-08 20:22:31,306 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-08 20:22:31,309 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-08 20:22:31,309 [DEBUG] httpcore.http11: response_closed.started
2025-10-08 20:22:31,309 [DEBUG] httpcore.http11: response_closed.complete
2025-10-08 20:22:31,309 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers([('date', 'Thu, 09 Oct 2025 01:22:31 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-allow-origin', '*'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-model', 'text-embedding-3-large'), ('openai-organization', 'personal-moaon6'), ('openai-processing-ms', '65'), ('openai-project', 'proj_xpqpZ6mXeDEwLbfYGvXUcwd5'), ('openai-version', '2020-10-01'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('via', 'envoy-router-797b6d7f75-b95mq'), ('x-envoy-upstream-service-time', '198'), ('x-ratelimit-limit-requests', '3000'), ('x-ratelimit-limit-tokens', '1000000'), ('x-ratelimit-remaining-requests', '2999'), ('x-ratelimit-remaining-tokens', '999899'), ('x-ratelimit-reset-requests', '20ms'), ('x-ratelimit-reset-tokens', '6ms'), ('x-request-id', 'req_f6d5f92b404241058d16cab95ce4b45e'), ('x-openai-proxy-wasm', 'v0.1'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=K0MuFD0CWLR1p4hXpvXa1UqYrEDjX6f2YZ3Wzgm6QOw-1759972951-1.0.1.1-d4r9oD578RLy_Xc.GApyWW30QIcxJ.wB9EoQqLyUMiqPwT3nk4paSFBWs6ZCTbNJmtBeGxs1ghfAuj7RmiamWz.mAkgn3mH4ZTiytOV..jc; path=/; expires=Thu, 09-Oct-25 01:52:31 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=8JAjylMJTus3jobYAVfR7NrwWOx4LAxLUgcU0Lof_gY-1759972951375-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '98ba114078a2f4ae-ORD'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-10-08 20:22:31,309 [DEBUG] openai._base_client: request_id: req_f6d5f92b404241058d16cab95ce4b45e
2025-10-08 20:22:31,310 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-08 20:22:31,310 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-08 20:22:31,311 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-08 20:22:31,311 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-08 20:22:31,311 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-08 20:22:31,322 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'content-type', b'application/json'), (b'content-length', b'5694'), (b'date', b'Thu, 09 Oct 2025 01:22:30 GMT')])
2025-10-08 20:22:31,322 [INFO] httpx: HTTP Request: POST http://localhost:8000/api/v2/tenants/default_tenant/databases/default_database/collections/87760c6d-637c-45d3-bbc4-b592e9ab0264/query "HTTP/1.1 200 OK"
2025-10-08 20:22:31,322 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-08 20:22:31,322 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-08 20:22:31,323 [DEBUG] httpcore.http11: response_closed.started
2025-10-08 20:22:31,323 [DEBUG] httpcore.http11: response_closed.complete
2025-10-08 20:22:31,326 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'idempotency_key': 'stainless-python-retry-79ca4e25-35ec-429c-928c-db2bb2663d28', 'json_data': {'messages': [{'content': '\n    You are an expert cover letter writer specializing in creating compelling, personalized cover letters that effectively connect a candidate\'s background to specific job opportunities.\n\n    Your task is to analyze the job posting, personalized resume, and retrieved context to generate ONLY the cover letter content paragraphs in plain LaTeX format.\n\n    POSITION: Python Developer\n    COMPANY: Ascendion\n    JOB POSTING:\n    About the job\nAbout Ascendion\nAscendion is a full-service digital engineering solutions company. We make and manage software platforms and products that power growth and deliver captivating experiences to consumers and employees. Our engineering, cloud, data, experience design, and talent solution capabilities accelerate transformation and impact for enterprise clients. Headquartered in New Jersey, our workforce of 6,000+ Ascenders delivers solutions from around the globe. Ascendion is built differently to engineer the next. Ascendion | Engineering to elevate life\nWe have a culture built on opportunity, inclusion, and a spirit of partnership. Come, change the world with us:\n¬∑ Build the coolest tech for world‚Äôs leading brands\n¬∑ Solve complex problems ‚Äì and learn new skills\n¬∑ Experience the power of transforming digital engineering for Fortune 500 clients\n¬∑ Master your craft with leading training programs and hands-on experience\nExperience a community of change makers!\nJoin a culture of high-performing innovators with endless ideas and a passion for tech. Our culture is the fabric of our company, and it is what makes us unique and diverse. The way we share ideas, learning, experiences, successes, and joy allows everyone to be their best at Ascendion.\nAbout the Role:\n\n\nJob Title : Python Developer\n\nLocation: Hybrid in Toronto, Canada\n\n \n\nLooking for Python Developer with Django, Flask and FastAPI\n\n\n\nSalary Range: The salary for this position is between $130,000 ‚Äì $140,000 annually. Factors which may affect pay within this range may include geography/market, skills, education, experience, and other qualifications of the successful candidate.\n\n\nBenefits: The Company offers the following benefits for this position, subject to applicable eligibility requirements: [medical insurance] [dental insurance] [vision insurance] [401(k) retirement plan] [long-term disability insurance] [short-term disability insurance] [5 personal days accrued each calendar year. The Paid time off benefits meet the paid sick and safe time laws that pertains to the City/ State] [10-15 days of paid vacation time] [6 paid holidays and 1 floating holiday per calendar year] [Ascendion Learning Management System]\n\n\nWant to change the world? Let us know.\nTell us about your experiences, education, and ambitions. Bring your knowledge, unique viewpoint, and creativity to the table. Let‚Äôs talk!\n\n    PERSONALIZED RESUME CONTENT:\n    RESUME: Amirreza Sokhankhosh\n‚ôÇphone431-293-6515 /envel‚å¢peamirreza.skhn@gmail.com /linkedinLinkedIn /githubGitHub ·ΩãCPortfolio\nHighlight of Relevant Skills\n‚Ä¢ Generative AI & LLMs: Designed and deployed applications powered by LLMs using LangChain, OpenAI API,\nvector databases (FAISS), and Ollama, with expertise in retrieval-augmented generation (RAG), fine-tuning\n(LoRA), and advanced prompting strategies (CoT, ReAct, Zero/Few-Shot).\n‚Ä¢ Machine Learning Engineering: Skilled in developing, training, and scaling ML models with PyTorch, Ten-\nsorFlow, Hugging Face Transformers, applying best practices in distributed AI, model evaluation, and MLOps\n(Docker, Kubernetes, CI/CD) for production-grade pipelines.\n‚Ä¢ NLP & Computer Vision: Applied deep learning to text and image data through projects in natural language\nprocessing, OCR, and image detection/segmentation , demonstrating the ability to handle multimodal ML\nchallenges.\n‚Ä¢ Full-Stack Development: Proven track record in building and integrating end-to-end applications, combining\nReact (TypeScript) for intuitive frontends with scalable backends in Flask, Django, NestJS, and databases such\nas PostgreSQL.\n‚Ä¢ APIs & Systems Design: Strong background in architecting and scalinginference APIs and cloud-native solutions,\nbridging robust backend services with user-friendly interfaces.\n‚Ä¢ Cloud & DevOps: Hands-on with AWS, Docker, Kubernetes, GitHub Actions, and CI/CD pipelines to ensure\nreliable and scalable deployments.\n‚Ä¢ Collaboration & Agile Practices: Experienced in Agile/Scrum workflows, cross-functional collaboration, code\nreviews, and delivering high-quality, production-ready systems in both research and industry settings.\nExperience\nUniversity of Manitoba Sep 2023 ‚Äì Jul 2025\nGraduate Research Assistant Winnipeg, Canada\n‚Ä¢ Designed/developed four novel distributed AI architectures, emphasizing secure, scalable & efficient system design\nand modular API development (TensorFlow, PyTorch, Hyperledger Fabric, Express.js/Flask).\n‚Ä¢ Achieved significant system optimizations: reduced communication overhead by 85.2% & increased fault tolerance\nby 62.7%, demonstrating expertise in building reliable AI systems.\n‚Ä¢ Authored/contributed to multiple research publications in top-tier IEEE venues.\nBobo App Ltd. May 2024 ‚Äì Aug 2024\nFull Stack Developer Intern Winnipeg, Canada\n‚Ä¢ Collaborated with a team at MILA in developing an efficient chatbot responsible for customer service.\n‚Ä¢ Accelerated product development by designing and implementingRESTful APIs using Supabase and PostgreSQL,\nenhancing backend functionality and data management.\n‚Ä¢ Automated data integration by developing a Python script to convert CSV data into executable SQL, significantly\nstreamlining database population.\n‚Ä¢ Ensured seamless full-stack integration through close collaboration with the front-end team to align API specifi-\ncations with user interface requirements.\n‚Ä¢ Contributed to agile workflow efficiency by utilizing the Atlassian suite ( Jira, Confluence) for task management,\ndocumentation, and team coordination.\nNadin Soft (Sadr Group Company) Jul 2020 ‚Äì Dec 2020\nFull-stack Developer Intern\n‚Ä¢ Drove the successful completion of a critical internal project, addressing key deficiencies in API security, authen-\ntication, and data modeling for production deployment.\n‚Ä¢ Developed robust RESTful APIs with AdonisJS and Express.js, implementing JWT authentication to secure\nuser access and enable core application functionalities.‚Ä¢ Designed and implemented highly accurate MySQL database schemas for precise tracking and management of em-\nployee working and non-working hours, foundational for the project‚Äôs business logic.\n‚Ä¢ Deployed fully functional features to the live production server and created thorough Swagger API documenta-\ntion, facilitating seamless internal integration and knowledge transfer.\n‚Ä¢ Contributed to an Agile Scrum development team by actively tracking and managing personal tasks within ClickUp,\nensuring efficient progress and clear communication within sprints and CI/CD pipelines.\nProjects\nMarkMate |React, Django, PostgreSQL, OpenAI API, LangChain|Link\n‚Ä¢ Built a full-stack web app for automated assignment grading using React, Django, and PostgreSQL.\n‚Ä¢ Integrated OCR and RAG-based LLM agents with custom test-case pipelines to generate consistent feedback.\n‚Ä¢ Reduced grading time and instructor effort by ‚âà80%, improving reliability and scalability.\nPaper Summarizer |Hugging Face Transformers, Ollama, OCR, LLMs|Link\n‚Ä¢ Engineered an LLM-powered summarization tool for academic papers with OCR + NLP pipelines .\n‚Ä¢ Applied LLaVA and LLaMA models for segmentation, entity extraction, and multimodal summarization.\n‚Ä¢ Generated holistic one-page summaries, improving research efficiency for academic users.\nUnified Image Evaluation Metric |PyTorch, NumPy|Link\n‚Ä¢ Designed a novel evaluation metric for generative AI, integrating precision, recall, quality, and diversity.\n‚Ä¢ Quantified generalization with KNN-based scoring and unified results via harmonic sum.\n‚Ä¢ Applied as a regularization term to WGAN-GP and Diffusion models , improving generalization.\nDigital Twin ‚Äì FL |TensorFlow, PyTorch Forecasting, Flask, Express.js|Link\n‚Ä¢ Developed a smart-building Digital Twin predicting CO2, humidity, and temperature across 76 IoT rooms.\n‚Ä¢ Implemented Temporal Fusion Transformers (TFT) for multivariate time series forecasting.\n‚Ä¢ Integrated into a federated learning framework, ensuring scalability and privacy-preserving analytics.\nFacial Landmark & Boundary Detection |OpenCV, TensorFlow, Faster R-CNN|Link\n‚Ä¢ Developed a computer vision pipeline for multi-face detection and landmark localization .\n‚Ä¢ Trained dual Faster R-CNN models to detect boundaries and extract 68 facial landmarks.\n‚Ä¢ Delivered robust performance for real-time facial feature extraction.\nEducation\nUniversity of Manitoba Sep 2023 ‚Äì Aug 2025\nMaster of Science in Computer Science (GPA: 4.4 / 4.5) Winnipeg, Canada\n‚Ä¢ Relevant Coursework: Security & Privacy, Deep Generative Modeling, Blockchain & Distributed Systems: A+\nK.N. Toosi University of Technology Sep 2018 ‚Äì Feb 2023\nBachelor of Science in Computer Engineering\nTechnical Skills\nAI / Machine Learning : TensorFlow, PyTorch, Flower, Numpy, Pandas, OpenCV, Transformers, LangChain, Lang-\nGraph, Scikit-learn, Keras, Matplotlib, TensorBoard, CUDA.\nLanguages: Python, C++, Java, JavaScript, TypeScript, Node JS, Solidity.\nCloud & DevOps: Docker, Kubernetes, Hyperledger Fabric, Git, GitHub, Linux, CI/CD, AWS.\nDatabases: PostgreSQL, MongoDB, MySQL, Redis, Db2, Supabase.\nWeb Frameworks: Back-end: Nest.JS, Django, Express.JS, Flask, Adonis.JS. Front-end: React, Tailwind\nTools & Methodologies: Jira, Confluence, Swagger, ClickUp, Agile, Scrum.\nCertificates\nInferring Causal Effects from Observational Data University of Pennsylvania|Credential\nReinforcement Learning Specialization University of Alberta|Credential\n\n    RETRIEVED CONTEXT FROM KNOWLEDGE BASE:\n    [Document(id=\'3325f8b5-cac8-47aa-ab0d-018c50ca37e5\', metadata={\'company\': \'Ascendion\', \'position\': \'Python Developer\', \'start_index\': 0, \'source\': \'cover letter\'}, page_content="I am excited to apply for the Python Developer position at \\\\textbf{Ascendion}. With my background in \\\\textbf{Python development} and experience in frameworks such as \\\\textbf{Django}, \\\\textbf{Flask}, and \\\\textbf{FastAPI}, I am eager to contribute to your team‚Äôs mission of transforming digital engineering and delivering captivating experiences. Ascendion\'s culture of innovation and its commitment to engineering that elevates life strongly resonate with my professional values and aspirations."), Document(id=\'15649aed-4073-49f5-807e-04fc96505ce0\', metadata={\'company\': \'Ascendion\', \'source\': \'cover letter\', \'position\': \'Python Developer\', \'start_index\': 0}, page_content="I am excited to apply for the Python Developer position at \\\\textbf{Ascendion}. With my background in \\\\textbf{Python development} and experience in frameworks such as \\\\textbf{Django}, \\\\textbf{Flask}, and \\\\textbf{FastAPI}, I am eager to contribute to your team‚Äôs mission of transforming digital engineering and delivering captivating experiences. Ascendion\'s culture of innovation and its commitment to engineering that elevates life strongly resonate with my professional values and aspirations."), Document(id=\'dbcc2e7c-246d-45e7-b5e7-41e0fd0b758a\', metadata={\'position\': \'Python Developer\', \'start_index\': 0, \'company\': \'Ascendion\', \'source\': \'cover letter\'}, page_content="I am excited to apply for the Python Developer position at \\\\textbf{Ascendion}. With my background in \\\\textbf{Python development} and extensive experience with frameworks such as \\\\textbf{Django}, \\\\textbf{Flask}, and \\\\textbf{FastAPI}, I am eager to contribute to your team\'s mission of transforming digital engineering and delivering captivating experiences. Ascendion\'s culture of innovation and its dedication to engineering that elevates life strongly resonate with my professional values and aspirations."), Document(id=\'c9163008-0ebe-447e-9477-80ed0da48ef6\', metadata={\'start_index\': 0, \'position\': \'Python Developer\', \'company\': \'Ascendion\', \'source\': \'cover letter\'}, page_content="I am excited to apply for the Python Developer position at \\\\textbf{Ascendion}. With my extensive experience in \\\\textbf{Python development} and proficiency in frameworks such as \\\\textbf{Django}, \\\\textbf{Flask}, and \\\\textbf{FastAPI}, I am eager to contribute to your team‚Äôs mission of transforming digital engineering and delivering captivating experiences. Ascendion\'s culture of innovation and its commitment to engineering that elevates life strongly resonate with my professional values and aspirations."), Document(id=\'9f633635-33d1-40f1-a506-22d8d27d73ba\', metadata={\'position\': \'Python Developer\', \'start_index\': 0, \'company\': \'Ascendion\', \'source\': \'cover letter\'}, page_content="I am excited to apply for the Python Developer position at \\\\textbf{Ascendion}. With my extensive experience in \\\\textbf{Python development} and proficiency in frameworks such as \\\\textbf{Django}, \\\\textbf{Flask}, and \\\\textbf{FastAPI}, I am eager to contribute to your team‚Äôs mission of transforming digital engineering and delivering captivating experiences. Ascendion\'s culture of innovation and its commitment to engineering that elevates life strongly resonate with my professional values and aspirations."), Document(id=\'39fc2647-7830-4dac-9b5d-b1aba7e35b2a\', metadata={\'position\': \'Python Developer\', \'company\': \'Ascendion\', \'start_index\': 0, \'source\': \'cover letter\'}, page_content="I am excited to apply for the Python Developer position at \\\\textbf{Ascendion}. With my extensive experience in \\\\textbf{Python development} and proficiency in frameworks such as \\\\textbf{Django}, \\\\textbf{Flask}, and \\\\textbf{FastAPI}, I am eager to contribute to your team‚Äôs mission of transforming digital engineering and delivering captivating experiences. Ascendion\'s culture of innovation and its commitment to engineering that elevates life strongly resonate with my professional values and aspirations."), Document(id=\'b4447976-35c8-4e28-9835-d87a11efa906\', metadata={\'start_index\': 0, \'source\': \'cover letter\', \'position\': \'Python Developer\', \'company\': \'Ascendion\'}, page_content=\'I am excited to apply for the Python Developer position at \\\\textbf{Ascendion}. With my background in \\\\textbf{Python development} and extensive experience in frameworks such as \\\\textbf{Django}, \\\\textbf{Flask}, and \\\\textbf{FastAPI}, I am eager to contribute to your team‚Äôs mission of transforming digital engineering and delivering captivating experiences.\\n\\nIn my recent projects, I have built scalable and secure applications using \\\\textbf{Python} and its frameworks, aligning with your requirements. For example, in my \\\\textbf{Mini Task Manager} project, I developed a token-based authentication system using \\\\textbf{Django REST Framework}, which resulted in a 25\\\\% increase in user engagement. Furthermore, my proficiency with \\\\textbf{Docker} and \\\\textbf{Kubernetes} has enabled me to reduce setup times by 30\\\\%, preparing me for the dynamic challenges outlined in your job posting.\'), Document(id=\'b35b20df-30ed-4c58-ba25-4ad9f0949211\', metadata={\'start_index\': 1497, \'source\': \'cover letter\', \'company\': \'Ascendion\', \'position\': \'Python Developer\'}, page_content="I am enthusiastic about the opportunity to contribute to \\\\textbf{Ascendion}\'s mission by bringing my skills to build advanced digital solutions. My background in \\\\textbf{distributed systems} and passion for \\\\textbf{digital engineering} uniquely position me to make significant contributions to your team. I am excited to bring my perspective and technical expertise to Ascendion, collaborating to create technology that elevates life.")]\n                                                       \n    INSTRUCTIONS:\n    1. Analyze the job posting to identify:\n       - Company mission, values, and culture\n       - Key technical requirements and preferred technologies\n       - Required experience level and responsibilities\n       - Specific skills and qualifications sought\n\n    2. Use the personalized resume content to:\n       - Highlight the most relevant experiences and achievements\n       - Showcase technical skills that match job requirements\n       - Reference specific projects that demonstrate required capabilities\n       - Quantify accomplishments where possible\n\n    3. Leverage the retrieved context to:\n       - Add depth and authenticity to your statements\n       - Reference relevant research, projects, or experiences not in the resume\n       - Demonstrate domain knowledge and passion for the field\n       - Show progression and learning from past experiences\n\n    4. Follow the template structure but adapt content to:\n       - Match the company\'s tone and industry language\n       - Create a narrative that connects past experiences to future contributions\n       - Show genuine enthusiasm for the specific role and company\n       - Address any potential gaps or explain career transitions\n\n\n    CRITICAL OUTPUT REQUIREMENTS:\n    - Generate ONLY the cover letter content paragraphs\n    - DO NOT include any LaTeX document structure (\\documentclass, \\begin{document}, \\begin{letter}, \\end{letter}, \\end{document})\n    - DO NOT include any explanations, introductions, or meta-commentary\n    - DO NOT include salutations like "Dear Hiring Manager" or closings like "Sincerely"\n    - Start directly with the first paragraph content\n    - End with the last paragraph content\n    - Use clean paragraph breaks (double newlines) between paragraphs\n\n    CONTENT STRUCTURE:\n    Write exactly 3-4 paragraphs of cover letter content:\n\n    Paragraph 1: Express enthusiasm for the specific role and company, briefly state your relevant background and why you\'re applying.\n\n    Paragraph 2: Highlight your most relevant technical experiences and projects with specific examples that match the job requirements.\n\n    Paragraph 3: Demonstrate alignment with the company\'s mission and technology stack, referencing retrieved context to show deeper knowledge and genuine interest.\n\n    Paragraph 4 (optional): Reiterate enthusiasm and mention specific contributions you can make to the team and company.\n\n                                                       \n    COVER LETTER STRUCTURE:\n    1. Opening paragraph: Express enthusiasm for the specific role and company, briefly state your relevant background\n    2. Body paragraph 1: Highlight relevant technical experience and projects with specific examples\n    3. Body paragraph 2: Demonstrate alignment with company mission/technology stack, reference retrieved context for depth\n    4. Closing paragraph: Reiterate enthusiasm, mention specific contributions you can make, professional closing\n\n    TONE AND STYLE:\n    - Professional yet enthusiastic\n    - Confident but not boastful\n    - Specific and detailed, not generic\n    - Forward-looking and solution-oriented\n    - Authentic and genuine\n    LATEX FORMATTING REQUIREMENTS:\n    - Use proper LaTeX escaping: \\& instead of & for ampersands\n    - Use \\% for percentages in text  \n    - Use \\textbf{} for emphasizing key technologies, company names, and achievements\n    - Write in clean, readable paragraph format\n    - Use standard paragraph separation (double newlines)\n\n    CONTENT GUIDELINES:\n    - Reference specific technologies, frameworks, and methodologies from the job posting\n    - Use metrics and quantified achievements where available\n    - Show understanding of the company\'s challenges and how you can help\n    - Demonstrate continuous learning and adaptability\n    - Connect past experiences to future potential contributions\n    - Use retrieved context to add unique insights or relevant background\n    - Be professional yet enthusiastic, confident but not boastful\n    - Make it specific and detailed, not generic\n\n    OUTPUT FORMAT EXAMPLE:\n    I am excited to apply for the {position} position at \\textbf{{company name}}. With my background in \\textbf{relevant technology} and experience in \\textbf{relevant domain}, I am eager to contribute to your team\'s mission of advancing \\textbf{company focus area}.\n\n    In my recent projects, I have built scalable applications using \\textbf{specific technologies} that align with your requirements. For example, in my \\textbf{project name} project, I developed \\textbf{specific implementation} that resulted in \\textbf{quantified outcome}. My experience with \\textbf{relevant technology stack} has prepared me to tackle the challenges outlined in your job posting.\n\n    I am particularly drawn to \\textbf{{company name}}\'s commitment to \\textbf{company values/mission}. My research in \\textbf{relevant area from context} has given me deep insights into \\textbf{relevant domain knowledge}, and I am excited about the opportunity to apply this knowledge in a production environment where I can help \\textbf{specific company goals}.\n\n    Generate the cover letter content paragraphs following this exact format:\n    ', 'role': 'user'}], 'model': 'gpt-4o', 'stream': False}}
2025-10-08 20:22:31,327 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-10-08 20:22:31,327 [DEBUG] httpcore.connection: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
2025-10-08 20:22:31,350 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): us.i.posthog.com:443
2025-10-08 20:22:31,357 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x123c81690>
2025-10-08 20:22:31,357 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x121b63260> server_hostname='api.openai.com' timeout=None
2025-10-08 20:22:31,393 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x123c81ad0>
2025-10-08 20:22:31,393 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-08 20:22:31,393 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-08 20:22:31,393 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-08 20:22:31,393 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-08 20:22:31,393 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-08 20:22:31,613 [DEBUG] urllib3.connectionpool: https://us.i.posthog.com:443 "POST /batch/ HTTP/1.1" 200 15
2025-10-08 20:22:37,017 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 09 Oct 2025 01:22:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'personal-moaon6'), (b'openai-processing-ms', b'5306'), (b'openai-project', b'proj_xpqpZ6mXeDEwLbfYGvXUcwd5'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'5473'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'24744'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'10.512s'), (b'x-request-id', b'req_35ed2a93264b48c3860122690bb1a8c4'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=BrPCYlZ08G431WUmR0xsk.4ccjnr2SzUeswZALxWrsA-1759972957-1.0.1.1-NZAe1DRnsaqsesPeGCsHL3yAWYqh_Vloo8NF0lo6CVYD6bpCXuBeG_jaSem5dQ0cx2qPqQ9n.E2ZdqFO.t_FyzfqKB0vihHhyauQr5iyTMA; path=/; expires=Thu, 09-Oct-25 01:52:37 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=e3JpE2VAWPOC5zF4nRzLeMkiMsvaDqJg9jnPDTIC3HE-1759972957087-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'98ba1142eb13f8d7-ORD'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-10-08 20:22:37,019 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-10-08 20:22:37,019 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-08 20:22:37,020 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-08 20:22:37,020 [DEBUG] httpcore.http11: response_closed.started
2025-10-08 20:22:37,020 [DEBUG] httpcore.http11: response_closed.complete
2025-10-08 20:22:37,020 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 09 Oct 2025 01:22:37 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'personal-moaon6'), ('openai-processing-ms', '5306'), ('openai-project', 'proj_xpqpZ6mXeDEwLbfYGvXUcwd5'), ('openai-version', '2020-10-01'), ('x-envoy-upstream-service-time', '5473'), ('x-ratelimit-limit-requests', '500'), ('x-ratelimit-limit-tokens', '30000'), ('x-ratelimit-remaining-requests', '499'), ('x-ratelimit-remaining-tokens', '24744'), ('x-ratelimit-reset-requests', '120ms'), ('x-ratelimit-reset-tokens', '10.512s'), ('x-request-id', 'req_35ed2a93264b48c3860122690bb1a8c4'), ('x-openai-proxy-wasm', 'v0.1'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=BrPCYlZ08G431WUmR0xsk.4ccjnr2SzUeswZALxWrsA-1759972957-1.0.1.1-NZAe1DRnsaqsesPeGCsHL3yAWYqh_Vloo8NF0lo6CVYD6bpCXuBeG_jaSem5dQ0cx2qPqQ9n.E2ZdqFO.t_FyzfqKB0vihHhyauQr5iyTMA; path=/; expires=Thu, 09-Oct-25 01:52:37 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=e3JpE2VAWPOC5zF4nRzLeMkiMsvaDqJg9jnPDTIC3HE-1759972957087-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '98ba1142eb13f8d7-ORD'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-10-08 20:22:37,020 [DEBUG] openai._base_client: request_id: req_35ed2a93264b48c3860122690bb1a8c4
2025-10-08 20:22:38,433 [INFO] chromadb.telemetry.product.posthog: Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-10-08 20:22:38,439 [DEBUG] chromadb.config: Starting component System
2025-10-08 20:22:38,439 [DEBUG] chromadb.config: Starting component Posthog
2025-10-08 20:22:38,439 [DEBUG] chromadb.config: Starting component OpenTelemetryClient
2025-10-08 20:22:38,439 [DEBUG] chromadb.config: Starting component FastAPI
2025-10-08 20:22:38,439 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=8000 local_address=None timeout=None socket_options=None
2025-10-08 20:22:38,441 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x123c22510>
2025-10-08 20:22:38,441 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-08 20:22:38,442 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-08 20:22:38,442 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-08 20:22:38,442 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-08 20:22:38,442 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-08 20:22:38,442 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'content-type', b'application/json'), (b'content-length', b'73'), (b'date', b'Thu, 09 Oct 2025 01:22:38 GMT')])
2025-10-08 20:22:38,442 [INFO] httpx: HTTP Request: GET http://localhost:8000/api/v2/auth/identity "HTTP/1.1 200 OK"
2025-10-08 20:22:38,442 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-08 20:22:38,442 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-08 20:22:38,442 [DEBUG] httpcore.http11: response_closed.started
2025-10-08 20:22:38,442 [DEBUG] httpcore.http11: response_closed.complete
2025-10-08 20:22:38,443 [INFO] chromadb.telemetry.product.posthog: Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-10-08 20:22:38,449 [DEBUG] chromadb.config: Starting component System
2025-10-08 20:22:38,449 [DEBUG] chromadb.config: Starting component Posthog
2025-10-08 20:22:38,449 [DEBUG] chromadb.config: Starting component OpenTelemetryClient
2025-10-08 20:22:38,449 [DEBUG] chromadb.config: Starting component FastAPI
2025-10-08 20:22:38,449 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=8000 local_address=None timeout=None socket_options=None
2025-10-08 20:22:38,451 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x123c28350>
2025-10-08 20:22:38,452 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-08 20:22:38,452 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-08 20:22:38,452 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-08 20:22:38,452 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-08 20:22:38,452 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-08 20:22:38,452 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'content-type', b'application/json'), (b'content-length', b'46'), (b'date', b'Thu, 09 Oct 2025 01:22:38 GMT')])
2025-10-08 20:22:38,452 [INFO] httpx: HTTP Request: GET http://localhost:8000/api/v2/tenants/default_tenant "HTTP/1.1 200 OK"
2025-10-08 20:22:38,452 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-08 20:22:38,453 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-08 20:22:38,453 [DEBUG] httpcore.http11: response_closed.started
2025-10-08 20:22:38,453 [DEBUG] httpcore.http11: response_closed.complete
2025-10-08 20:22:38,453 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-08 20:22:38,453 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-08 20:22:38,453 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-08 20:22:38,453 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-08 20:22:38,453 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-08 20:22:38,453 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'content-type', b'application/json'), (b'content-length', b'97'), (b'date', b'Thu, 09 Oct 2025 01:22:38 GMT')])
2025-10-08 20:22:38,453 [INFO] httpx: HTTP Request: GET http://localhost:8000/api/v2/tenants/default_tenant/databases/default_database "HTTP/1.1 200 OK"
2025-10-08 20:22:38,453 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-08 20:22:38,453 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-08 20:22:38,453 [DEBUG] httpcore.http11: response_closed.started
2025-10-08 20:22:38,454 [DEBUG] httpcore.http11: response_closed.complete
2025-10-08 20:22:38,455 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-08 20:22:38,455 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-08 20:22:38,455 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-08 20:22:38,455 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-08 20:22:38,455 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-08 20:22:38,458 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'content-type', b'application/json'), (b'content-length', b'363'), (b'date', b'Thu, 09 Oct 2025 01:22:38 GMT')])
2025-10-08 20:22:38,458 [INFO] httpx: HTTP Request: POST http://localhost:8000/api/v2/tenants/default_tenant/databases/default_database/collections "HTTP/1.1 200 OK"
2025-10-08 20:22:38,458 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-08 20:22:38,458 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-08 20:22:38,458 [DEBUG] httpcore.http11: response_closed.started
2025-10-08 20:22:38,458 [DEBUG] httpcore.http11: response_closed.complete
2025-10-08 20:22:38,462 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'idempotency_key': 'stainless-python-retry-f7b0840d-6f36-49dc-ba5c-92f994277d9b', 'post_parser': <function Embeddings.create.<locals>.parser at 0x121ff8220>, 'json_data': {'input': [[40, 1097, 12304, 311, 3881, 369, 279, 13325, 25922, 2361, 520, 1144, 1342, 13536, 90, 41203, 408, 290, 7966, 3161, 856, 4092, 304, 1144, 1342, 13536, 90, 31380, 4500, 92, 323, 3217, 304, 49125, 1778, 439, 1144, 1342, 13536, 90, 35, 5970, 2186, 1144, 1342, 13536, 90, 3968, 1091, 2186, 323, 1144, 1342, 13536, 90, 33274, 7227, 2186, 358, 1097, 24450, 311, 17210, 311, 701, 2128, 596, 9131, 315, 46890, 7528, 15009, 323, 24944, 86282, 11704, 13, 40660, 408, 290, 596, 7829, 315, 19297, 323, 1202, 15507, 311, 15009, 430, 12231, 988, 2324, 16917, 89986, 449, 856, 6721, 2819, 323, 58522, 13], [644, 856, 3293, 7224, 11, 358, 617, 5918, 69311, 323, 9966, 8522, 1701, 1144, 1342, 13536, 90, 31380, 92, 323, 1202, 49125, 11, 5398, 287, 449, 701, 8670, 13, 1789, 3187, 11, 304, 856, 1144, 1342, 13536, 90, 9126, 97742, 92, 2447, 11, 358, 8040, 459, 28598, 16720, 66288, 1887, 1701, 1144, 1342, 13536, 90, 15143, 2186, 1144, 1342, 13536, 90, 35, 5970, 2186, 323, 1144, 1342, 13536, 90, 4226, 60896, 2186, 18189, 66288, 892, 555, 13489, 220, 1490, 59, 14697, 24296, 11, 856, 3217, 449, 1144, 1342, 13536, 90, 35, 13973, 92, 323, 1144, 1342, 13536, 90, 42, 30927, 92, 9147, 757, 311, 4305, 11297, 24047, 10105, 11, 20646, 757, 369, 279, 8915, 11774, 520, 40660, 408, 290, 13], [40, 1097, 8104, 15107, 311, 1144, 1342, 13536, 90, 41203, 408, 290, 11923, 82, 15507, 311, 6968, 5557, 430, 12231, 988, 2324, 323, 701, 25679, 389, 7528, 15009, 369, 46331, 220, 2636, 8403, 13, 3092, 3217, 304, 1144, 1342, 13536, 90, 63475, 6067, 92, 323, 5780, 6975, 5825, 757, 449, 279, 7512, 4460, 311, 25555, 304, 420, 3560, 13, 358, 1097, 12304, 922, 279, 22199, 315, 19486, 14713, 48448, 15592, 323, 5780, 6975, 14645, 311, 4726, 40660, 408, 290, 596, 18699, 9021, 323, 11886, 6485, 5435, 369, 701, 8403, 382, 40, 1097, 42702, 922, 279, 6776, 311, 17210, 311, 1144, 1342, 13536, 90, 41203, 408, 290, 11923, 82, 9131, 555, 12967, 856, 7512, 311, 1977, 11084, 7528, 10105, 13, 3161, 856, 3831, 4092, 304, 13325, 323, 5552, 14645, 11, 358, 1097, 16913, 430, 358, 649, 1304, 14247, 323, 5199, 19564, 311, 701, 2128, 11, 10695, 40660, 408, 290, 6493, 86282, 323, 14713, 48448, 10105, 13]], 'model': 'text-embedding-3-large', 'encoding_format': 'base64'}}
2025-10-08 20:22:38,462 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2025-10-08 20:22:38,462 [DEBUG] httpcore.connection: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
2025-10-08 20:22:38,490 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x123c31190>
2025-10-08 20:22:38,490 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x121f2f020> server_hostname='api.openai.com' timeout=None
2025-10-08 20:22:38,527 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x123c2ab50>
2025-10-08 20:22:38,527 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-08 20:22:38,528 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-08 20:22:38,528 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-08 20:22:38,528 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-08 20:22:38,528 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-08 20:22:38,727 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 09 Oct 2025 01:22:38 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-large'), (b'openai-organization', b'personal-moaon6'), (b'openai-processing-ms', b'102'), (b'openai-project', b'proj_xpqpZ6mXeDEwLbfYGvXUcwd5'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-76f88f4767-b4zgv'), (b'x-envoy-upstream-service-time', b'123'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999623'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'22ms'), (b'x-request-id', b'req_7022852cbbee45b1a8ffeb78025d4cc9'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=a28QBEKlBKYVNVkpFjZPYgS5CudSYiaifNErHqVXN4M-1759972958-1.0.1.1-SRwuhbW_nSr_BoN4ZCBFldRZ7ihOb1Q10E.8XVvasHh9XnSa4HdWibyQTuinozzDtWHo9kUxuTk1TpjN9B1wvmc3aqw1Tq76N1ZSOtdy0cI; path=/; expires=Thu, 09-Oct-25 01:52:38 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=UFncv8jjZvOqE8d5DZpKiIpMCUyaQpCIDyP3LeI8q.Q-1759972958801-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'98ba116f79a83ef3-ORD'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-10-08 20:22:38,728 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-10-08 20:22:38,729 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-08 20:22:38,733 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-08 20:22:38,733 [DEBUG] httpcore.http11: response_closed.started
2025-10-08 20:22:38,733 [DEBUG] httpcore.http11: response_closed.complete
2025-10-08 20:22:38,734 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers([('date', 'Thu, 09 Oct 2025 01:22:38 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-allow-origin', '*'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-model', 'text-embedding-3-large'), ('openai-organization', 'personal-moaon6'), ('openai-processing-ms', '102'), ('openai-project', 'proj_xpqpZ6mXeDEwLbfYGvXUcwd5'), ('openai-version', '2020-10-01'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('via', 'envoy-router-76f88f4767-b4zgv'), ('x-envoy-upstream-service-time', '123'), ('x-ratelimit-limit-requests', '3000'), ('x-ratelimit-limit-tokens', '1000000'), ('x-ratelimit-remaining-requests', '2999'), ('x-ratelimit-remaining-tokens', '999623'), ('x-ratelimit-reset-requests', '20ms'), ('x-ratelimit-reset-tokens', '22ms'), ('x-request-id', 'req_7022852cbbee45b1a8ffeb78025d4cc9'), ('x-openai-proxy-wasm', 'v0.1'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=a28QBEKlBKYVNVkpFjZPYgS5CudSYiaifNErHqVXN4M-1759972958-1.0.1.1-SRwuhbW_nSr_BoN4ZCBFldRZ7ihOb1Q10E.8XVvasHh9XnSa4HdWibyQTuinozzDtWHo9kUxuTk1TpjN9B1wvmc3aqw1Tq76N1ZSOtdy0cI; path=/; expires=Thu, 09-Oct-25 01:52:38 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=UFncv8jjZvOqE8d5DZpKiIpMCUyaQpCIDyP3LeI8q.Q-1759972958801-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '98ba116f79a83ef3-ORD'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-10-08 20:22:38,734 [DEBUG] openai._base_client: request_id: req_7022852cbbee45b1a8ffeb78025d4cc9
2025-10-08 20:22:38,735 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-08 20:22:38,735 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-08 20:22:38,735 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-08 20:22:38,735 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-08 20:22:38,735 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-08 20:22:38,735 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'content-type', b'application/json'), (b'content-length', b'55'), (b'date', b'Thu, 09 Oct 2025 01:22:38 GMT')])
2025-10-08 20:22:38,735 [INFO] httpx: HTTP Request: GET http://localhost:8000/api/v2/pre-flight-checks "HTTP/1.1 200 OK"
2025-10-08 20:22:38,735 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-08 20:22:38,735 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-08 20:22:38,735 [DEBUG] httpcore.http11: response_closed.started
2025-10-08 20:22:38,735 [DEBUG] httpcore.http11: response_closed.complete
2025-10-08 20:22:38,736 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-08 20:22:38,736 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-08 20:22:38,736 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-08 20:22:38,736 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-08 20:22:38,736 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-08 20:22:38,757 [DEBUG] urllib3.connectionpool: https://us.i.posthog.com:443 "POST /batch/ HTTP/1.1" 200 15
2025-10-08 20:22:38,769 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'content-type', b'application/json'), (b'content-length', b'2'), (b'date', b'Thu, 09 Oct 2025 01:22:38 GMT')])
2025-10-08 20:22:38,770 [INFO] httpx: HTTP Request: POST http://localhost:8000/api/v2/tenants/default_tenant/databases/default_database/collections/87760c6d-637c-45d3-bbc4-b592e9ab0264/upsert "HTTP/1.1 200 OK"
2025-10-08 20:22:38,770 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-08 20:22:38,770 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-08 20:22:38,770 [DEBUG] httpcore.http11: response_closed.started
2025-10-08 20:22:38,770 [DEBUG] httpcore.http11: response_closed.complete
2025-10-08 20:22:38,786 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'idempotency_key': 'stainless-python-retry-06c4cbac-7ce3-4ed3-be3b-ac240d846356', 'post_parser': <function Embeddings.create.<locals>.parser at 0x10678dd00>, 'json_data': {'input': 'Company: Ascendion. Position: Python Developer. Description: About the job\nAbout Ascendion\nAscendion is a full-service digital engineering solutions company. We make and manage software platforms and products that power growth and deliver captivating experiences to consumers and employees. Our engineering, cloud, data, experience design, and talent solution capabilities accelerate transformation and impact for enterprise clients. Headquartered in New Jersey, our workforce of 6,000+ Ascenders delivers solutions from around the globe. Ascendion is built differently to engineer the next. Ascendion | Engineering to elevate life\nWe have a culture built on opportunity, inclusion, and a spirit of partnership. Come, change the world with us:\n¬∑ Build the coolest tech for world‚Äôs leading brands\n¬∑ Solve complex problems ‚Äì and learn new skills\n¬∑ Experience the power of transforming digital engineering for Fortune 500 clients\n¬∑ Master your craft with leading training programs and hands-on experience\nExperience a community of change makers!\nJoin a culture of high-performing innovators with endless ideas and a passion for tech. Our culture is the fabric of our company, and it is what makes us unique and diverse. The way we share ideas, learning, experiences, successes, and joy allows everyone to be their best at Ascendion.\nAbout the Role:\n\n\nJob Title : Python Developer\n\nLocation: Hybrid in Toronto, Canada\n\n \n\nLooking for Python Developer with Django, Flask and FastAPI\n\n\n\nSalary Range: The salary for this position is between $130,000 ‚Äì $140,000 annually. Factors which may affect pay within this range may include geography/market, skills, education, experience, and other qualifications of the successful candidate.\n\n\nBenefits: The Company offers the following benefits for this position, subject to applicable eligibility requirements: [medical insurance] [dental insurance] [vision insurance] [401(k) retirement plan] [long-term disability insurance] [short-term disability insurance] [5 personal days accrued each calendar year. The Paid time off benefits meet the paid sick and safe time laws that pertains to the City/ State] [10-15 days of paid vacation time] [6 paid holidays and 1 floating holiday per calendar year] [Ascendion Learning Management System]\n\n\nWant to change the world? Let us know.\nTell us about your experiences, education, and ambitions. Bring your knowledge, unique viewpoint, and creativity to the table. Let‚Äôs talk!', 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}
2025-10-08 20:22:38,787 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2025-10-08 20:22:38,787 [DEBUG] httpcore.connection: close.started
2025-10-08 20:22:38,787 [DEBUG] httpcore.connection: close.complete
2025-10-08 20:22:38,787 [DEBUG] httpcore.connection: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-10-08 20:22:38,826 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x123c22ed0>
2025-10-08 20:22:38,826 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x107dff2f0> server_hostname='api.openai.com' timeout=5.0
2025-10-08 20:22:38,862 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x121ea3910>
2025-10-08 20:22:38,862 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-08 20:22:38,862 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-08 20:22:38,862 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-08 20:22:38,862 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-08 20:22:38,862 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-08 20:22:39,121 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 09 Oct 2025 01:22:39 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'personal-moaon6'), (b'openai-processing-ms', b'83'), (b'openai-project', b'proj_xpqpZ6mXeDEwLbfYGvXUcwd5'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-797b6d7f75-htpvc'), (b'x-envoy-upstream-service-time', b'148'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999384'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'36ms'), (b'x-request-id', b'req_95a0dfe4adac42d48523040ff076a618'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'98ba11719dfdae77-ORD'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-10-08 20:22:39,122 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-10-08 20:22:39,122 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-08 20:22:39,123 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-08 20:22:39,123 [DEBUG] httpcore.http11: response_closed.started
2025-10-08 20:22:39,123 [DEBUG] httpcore.http11: response_closed.complete
2025-10-08 20:22:39,124 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers({'date': 'Thu, 09 Oct 2025 01:22:39 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-3-small', 'openai-organization': 'personal-moaon6', 'openai-processing-ms': '83', 'openai-project': 'proj_xpqpZ6mXeDEwLbfYGvXUcwd5', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'via': 'envoy-router-797b6d7f75-htpvc', 'x-envoy-upstream-service-time': '148', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '1000000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '999384', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '36ms', 'x-request-id': 'req_95a0dfe4adac42d48523040ff076a618', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '98ba11719dfdae77-ORD', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-10-08 20:22:39,124 [DEBUG] openai._base_client: request_id: req_95a0dfe4adac42d48523040ff076a618
2025-10-08 20:22:39,147 [INFO] src.api.app: ‚úÖ POST /api/generate/cover-letter/ - 200 - 9.355s
2025-10-08 20:22:39,147 [WARNING] src.api.app: üêå Slow request: POST /api/generate/cover-letter/ took 9.355s
2025-10-08 20:22:39,148 [INFO] werkzeug: 127.0.0.1 - - [08/Oct/2025 20:22:39] "POST /api/generate/cover-letter/ HTTP/1.1" 200 -
2025-10-08 20:22:52,122 [INFO] src.api.app: üåê GET /api/resumes/generated/Python Developer.pdf - 127.0.0.1
2025-10-08 20:22:52,123 [INFO] src.api.app: ‚ùå GET /api/resumes/generated/Python Developer.pdf - 404 - 0.002s
2025-10-08 20:22:52,124 [INFO] werkzeug: 127.0.0.1 - - [08/Oct/2025 20:22:52] "[33mGET /api/resumes/generated/Python%20Developer.pdf HTTP/1.1[0m" 404 -
2025-10-08 20:22:54,445 [INFO] src.api.app: üåê GET /api/resumes/generated/Python Developer.pdf - 127.0.0.1
2025-10-08 20:22:54,446 [INFO] src.api.app: ‚ùå GET /api/resumes/generated/Python Developer.pdf - 404 - 0.001s
2025-10-08 20:22:54,447 [INFO] werkzeug: 127.0.0.1 - - [08/Oct/2025 20:22:54] "[33mGET /api/resumes/generated/Python%20Developer.pdf HTTP/1.1[0m" 404 -
2025-10-08 20:22:57,670 [INFO] src.api.app: üåê GET /api/resumes/preview/ml-engineering - 127.0.0.1
2025-10-08 20:22:57,673 [INFO] src.api.app: ‚úÖ GET /api/resumes/preview/ml-engineering - 304 - 0.003s
2025-10-08 20:22:57,674 [INFO] werkzeug: 127.0.0.1 - - [08/Oct/2025 20:22:57] "[36mGET /api/resumes/preview/ml-engineering HTTP/1.1[0m" 304 -
2025-10-08 20:23:03,732 [INFO] src.api.app: üåê GET /api/resumes/preview/ml-engineering - 127.0.0.1
2025-10-08 20:23:03,733 [INFO] src.api.app: ‚úÖ GET /api/resumes/preview/ml-engineering - 304 - 0.001s
2025-10-08 20:23:03,736 [INFO] werkzeug: 127.0.0.1 - - [08/Oct/2025 20:23:03] "[36mGET /api/resumes/preview/ml-engineering HTTP/1.1[0m" 304 -
